{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"./FGDD.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate CSV files and import into neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_features = data.filter(regex='^HP')\n",
    "hp_features = hp_features.columns\n",
    "hpo_nodes = pd.DataFrame({\n",
    "    \"HpoId\": hp_features.tolist(),\n",
    "    \"Facialphenotypename\": hp_features.tolist(),\n",
    "    #\":LABEL\": \"FacialPhenotype\"\n",
    "})\n",
    "\n",
    "disease_feature = data[[\"Disease_id\", \"Disease_name\"]].dropna(axis=0).drop_duplicates()\n",
    "disease_id = disease_feature['Disease_id']\n",
    "disease_name = disease_feature['Disease_name']\n",
    "disease_nodes = pd.DataFrame({\n",
    "    \"DiseaseId\": disease_id,\n",
    "    \"name\": disease_name ,\n",
    "    #\":LABEL\": \"Disease\"\n",
    "})\n",
    "\n",
    "patient_id = data['patient_id']\n",
    "pmid = data['pmid']\n",
    "patient_number = data['patient_number']\n",
    "gender = data['gender']\n",
    "age = data['age']\n",
    "region = data['region']\n",
    "race = data['race']\n",
    "\n",
    "patient_nodes = pd.DataFrame({\n",
    "    \"PatientId\": patient_id,\n",
    "    \"pmid\": pmid,\n",
    "    \"patient_number\": patient_number,\n",
    "    \"gender\": gender,\n",
    "    \"age\": age,\n",
    "    \"region\": region,\n",
    "    \"race\": race,\n",
    "    #\":LABEL\": \"Patient\"\n",
    "})\n",
    "\n",
    "\n",
    "var_feature1 = data[[\"Variant_Gene_id_1\", \"Variant_Gene_name_1\", \"Variant_Gene_details_1\", \"Variant_Gene_chromosome_name_1\", \"Variant_Gene_chromosome_location_1\", \"Variant_Gene_exon_count_1\"]].drop_duplicates()\n",
    "var_feature2 = data[[\"Variant_Gene_id_2\", \"Variant_Gene_name_2\", \"Variant_Gene_details_2\", \"Variant_Gene_chromosome_name_2\", \"Variant_Gene_chromosome_location_2\", \"Variant_Gene_exon_count_2\"]].drop_duplicates()\n",
    "var_feature1_renamed = var_feature1.rename(columns=lambda x: x.replace(\"_1\", \"\"))\n",
    "var_feature2_renamed = var_feature2.rename(columns=lambda x: x.replace(\"_2\", \"\"))\n",
    "combined_features = pd.concat(\n",
    "    [var_feature1_renamed, var_feature2_renamed], \n",
    "    axis=0,  # 纵向合并\n",
    "    ignore_index=True  # 重置索引\n",
    ")\n",
    "var_features = combined_features.drop_duplicates()\n",
    "\n",
    "gene_id = var_features['Variant_Gene_id']\n",
    "gene_name = var_features['Variant_Gene_name']\n",
    "variation_details = var_features['Variant_Gene_details']\n",
    "chromosome = var_features['Variant_Gene_chromosome_name']\n",
    "chromosome_location = var_features['Variant_Gene_chromosome_location']\n",
    "chromosome_exon_count = var_features['Variant_Gene_exon_count']\n",
    "\n",
    "Variation_nodes = pd.DataFrame({\n",
    "    \"VariationId\": variation_details,\n",
    "    \"gene_id\": gene_id,\n",
    "    \"gene_name\": gene_name,\n",
    "    \"variation_details\": variation_details,\n",
    "    \"chromosome\": chromosome,\n",
    "    \"chromosome_location\": chromosome_location,\n",
    "    \"chromosome_exon_count\": chromosome_exon_count,\n",
    "    #\":LABEL\": \"Variation\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15085\\AppData\\Local\\Temp\\ipykernel_22280\\2691553354.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  diagnosed_with_relation = pd.concat([diagnosed_with_relation, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#:START_ID,:END_ID,:TYPE\n",
    "presents_relation = pd.DataFrame({\n",
    "    \"START_ID\": pd.Series(dtype='str'),\n",
    "    \"END_ID\": pd.Series(dtype='str'),\n",
    "    \"TYPE\": pd.Series(dtype='str'),\n",
    "})\n",
    "diagnosed_with_relation = pd.DataFrame({\n",
    "    \"START_ID\": pd.Series(dtype='str'),\n",
    "    \"END_ID\": pd.Series(dtype='str'),\n",
    "    \"TYPE\": pd.Series(dtype='str'),\n",
    "})\n",
    "\n",
    "fp_columns = data.filter(regex='^HP').columns\n",
    "for i in range(len(data)):\n",
    "    patient_id = data.loc[i]['patient_id']\n",
    "\n",
    "    # presents\n",
    "    row = data.loc[i, fp_columns]\n",
    "    fp_ids_mask = (row != 0)\n",
    "    fp_ids = row[fp_ids_mask].index.tolist()\n",
    "    for fpid in fp_ids:\n",
    "        new_row = pd.DataFrame({\"START_ID\": [patient_id], \"END_ID\": [fpid], \"TYPE\": [\"presents\"] })\n",
    "        presents_relation = pd.concat([presents_relation, new_row], ignore_index=True)\n",
    "\n",
    "    # diagnosed_with\n",
    "    disease_id = data.loc[i]['Disease_id']\n",
    "    new_row = pd.DataFrame({\"START_ID\": [patient_id], \"END_ID\": [disease_id], \"TYPE\": [\"diagnosed_with\"] })\n",
    "    diagnosed_with_relation = pd.concat([diagnosed_with_relation, new_row], ignore_index=True)\n",
    "\n",
    "diagnosed_with_relation = diagnosed_with_relation.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15085\\AppData\\Local\\Temp\\ipykernel_22280\\21126050.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  caused_by_relation = pd.concat([caused_by_relation, new_row], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>START_ID</th>\n",
       "      <th>END_ID</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c.3838C &gt; T; p. Arg1280Cys in exon 17</td>\n",
       "      <td>HP:0000252</td>\n",
       "      <td>leads_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c.3838C &gt; T; p. Arg1280Cys in exon 17</td>\n",
       "      <td>HP:0000340</td>\n",
       "      <td>leads_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c.456delC ,p.Gly153Alafs*34,in exon 1</td>\n",
       "      <td>HP:0000316</td>\n",
       "      <td>leads_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c.456delC ,p.Gly153Alafs*34,in exon 1</td>\n",
       "      <td>HP:0005280</td>\n",
       "      <td>leads_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c.456delC ,p.Gly153Alafs*34,in exon 1</td>\n",
       "      <td>HP:0000347</td>\n",
       "      <td>leads_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8428</th>\n",
       "      <td>c.154 G &gt; A,p (Asp52Asn)</td>\n",
       "      <td>HP:0045075</td>\n",
       "      <td>leads_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8429</th>\n",
       "      <td>c.154 G &gt; A,p (Asp52Asn)</td>\n",
       "      <td>HP:0000212</td>\n",
       "      <td>leads_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8430</th>\n",
       "      <td>c.154 G &gt; A,p (Asp52Asn)</td>\n",
       "      <td>HP:0006316</td>\n",
       "      <td>leads_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8431</th>\n",
       "      <td>c.154 G &gt; A,p (Asp52Asn)</td>\n",
       "      <td>HP:0045074</td>\n",
       "      <td>leads_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8432</th>\n",
       "      <td>c.154 G &gt; A,p (Asp52Asn)</td>\n",
       "      <td>HP:0000698</td>\n",
       "      <td>leads_to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7103 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   START_ID      END_ID      TYPE\n",
       "0     c.3838C > T; p. Arg1280Cys in exon 17  HP:0000252  leads_to\n",
       "1     c.3838C > T; p. Arg1280Cys in exon 17  HP:0000340  leads_to\n",
       "2     c.456delC ,p.Gly153Alafs*34,in exon 1  HP:0000316  leads_to\n",
       "3     c.456delC ,p.Gly153Alafs*34,in exon 1  HP:0005280  leads_to\n",
       "4     c.456delC ,p.Gly153Alafs*34,in exon 1  HP:0000347  leads_to\n",
       "...                                     ...         ...       ...\n",
       "8428               c.154 G > A,p (Asp52Asn)  HP:0045075  leads_to\n",
       "8429               c.154 G > A,p (Asp52Asn)  HP:0000212  leads_to\n",
       "8430               c.154 G > A,p (Asp52Asn)  HP:0006316  leads_to\n",
       "8431               c.154 G > A,p (Asp52Asn)  HP:0045074  leads_to\n",
       "8432               c.154 G > A,p (Asp52Asn)  HP:0000698  leads_to\n",
       "\n",
       "[7103 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caused_by_relation = pd.DataFrame({\n",
    "    \"START_ID\": pd.Series(dtype='str'),\n",
    "    \"END_ID\": pd.Series(dtype='str'),\n",
    "    \"TYPE\": pd.Series(dtype='str'),\n",
    "})\n",
    "leads_to_relation = pd.DataFrame({\n",
    "    \"START_ID\": pd.Series(dtype='str'),\n",
    "    \"END_ID\": pd.Series(dtype='str'),\n",
    "    \"TYPE\": pd.Series(dtype='str'),\n",
    "})\n",
    "\n",
    "row_length = 0\n",
    "fp_columns = data.filter(regex='^HP').columns\n",
    "for var_id in var_features['Variant_Gene_details']:\n",
    "    # var_id = var_features.loc[i]['Variant_Gene_details']\n",
    "\n",
    "    # caused_by\n",
    "    data_fliter = data[~data['Disease_id'].isnull()]\n",
    "    disease_id = data_fliter.loc[(data_fliter['Variant_Gene_details_1'] == var_id) | (data_fliter['Variant_Gene_details_2'] == var_id),'Disease_id']\n",
    "    for id in disease_id:\n",
    "        new_row = pd.DataFrame({\"START_ID\": [var_id], \"END_ID\": [id], \"TYPE\": [\"caused_by\"] })\n",
    "        caused_by_relation = pd.concat([caused_by_relation, new_row], ignore_index=True)\n",
    "    \n",
    "    # 这里有一部分重复统计了\n",
    "    # leads_to\n",
    "    rows = data.loc[(data['Variant_Gene_details_1'] == var_id) | (data['Variant_Gene_details_2'] == var_id), fp_columns]\n",
    "    row_length += len(rows)\n",
    "    for _, row in rows.iterrows():\n",
    "        #row = rows.loc[i]\n",
    "        fp_ids_mask = (row != 0)\n",
    "        fp_ids = row[fp_ids_mask].index.tolist()\n",
    "        for fpid in fp_ids:\n",
    "            new_row = pd.DataFrame({\"START_ID\": [var_id], \"END_ID\": [fpid], \"TYPE\": [\"leads_to\"] })\n",
    "            leads_to_relation = pd.concat([leads_to_relation, new_row], ignore_index=True)\n",
    "leads_to_relation.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_nodes.to_csv(\"phenotype_nodes.csv\", index=False)\n",
    "disease_nodes.to_csv(\"disease_nodes.csv\", index=False)\n",
    "patient_nodes.to_csv(\"patient_nodes.csv\", index=False)\n",
    "Variation_nodes.to_csv(\"variation_nodes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "presents_relation.to_csv(\"presents_relation.csv\", index=False)\n",
    "diagnosed_with_relation.to_csv(\"diagnosed_with_relation.csv\", index=False)\n",
    "caused_by_relation.to_csv(\"caused_by_relation.csv\", index=False)\n",
    "leads_to_relation.to_csv(\"leads_to_relation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting csv files into the neo4j import directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run below cypher statments in neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD CSV WITH HEADERS FROM 'file:///disease_nodes.csv' AS row\n",
    "CREATE (:Disease {\n",
    "  DiseaseId: row.DiseaseId,\n",
    "  name: row.name\n",
    "});\n",
    "\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM 'file:///patient_nodes.csv' AS row\n",
    "CREATE (:Patient {\n",
    "  PatientId: row.PatientId,\n",
    "  pmid: row.pmid,\n",
    "  patient_number: row.patient_number,\n",
    "  gender: row.gender,\n",
    "  age: toFloat(row.age),\n",
    "  region: row.region,\n",
    "  race: row.race\n",
    "});\n",
    "\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM 'file:///phenotype_nodes.csv' AS row\n",
    "CREATE (:Phenotype {\n",
    "  HpoId: row.HpoId,\n",
    "  Facialphenotypename: row.Facialphenotypename\n",
    "});\n",
    "\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM 'file:///variation_nodes.csv' AS row\n",
    "CREATE (:Variation {\n",
    "  VariationId: row.VariationId,\n",
    "  gene_id: row.gene_id,\n",
    "  gene_name: row.gene_name,\n",
    "  variation_details: row.variation_details,\n",
    "  chromosome: row.chromosome,\n",
    "  chromosome_location: row.chromosome_location,\n",
    "  chromosome_exon_count: row.chromosome_exon_count\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD CSV WITH HEADERS FROM 'file:///leads_to_relation.csv' AS row\n",
    "MATCH (n1:Variation {VariationId: row.START_ID})\n",
    "MATCH (n2:Phenotype {HpoId: row.END_ID})\n",
    "CREATE (n1)-[r: leads_to]->(n2)\n",
    "RETURN count(r);\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM 'file:///diagnosed_with_relation.csv' AS row\n",
    "MATCH (n1:Patient {PatientId: row.START_ID})\n",
    "MATCH (n2:Disease {DiseaseId: row.END_ID})\n",
    "CREATE (n1)-[r: diagnosed_with]->(n2)\n",
    "RETURN count(r);\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM 'file:///presents_relation.csv' AS row\n",
    "MATCH (n1:Patient   {PatientId: row.START_ID})\n",
    "MATCH (n2:Phenotype {HpoId: row.END_ID})\n",
    "CREATE (n1)-[r: presents]->(n2)\n",
    "RETURN count(r);\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM 'file:///caused_by_relation.csv' AS row\n",
    "MATCH (n1:Disease {DiseaseId: row.END_ID})\n",
    "MATCH (n2:Variation {VariationId: row.START_ID})\n",
    "CREATE (n1)-[r: caused_by]->(n2)\n",
    "RETURN count(r);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
