{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch  \n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim  \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from pytorch_tabnet import tab_network\n",
    "from pytorch_tabnet.utils import create_group_matrix\n",
    "from rtdl_revisiting_models import FTTransformer\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "data = pd.read_csv('FGDD.csv')\n",
    "data = data[~data['Disease_id'].isnull()]\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------ pre-processing ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Variant_Gene_id_1'].fillna(0, inplace=True)\n",
    "data['Variant_Gene_id_2'].fillna(0, inplace=True)\n",
    "\n",
    "data['Variant_Gene_id_1'] = data['Variant_Gene_id_1'].astype(int)\n",
    "data['Variant_Gene_id_1'] = data['Variant_Gene_id_1'].astype(str)\n",
    "data['Variant_Gene_id_2'] = data['Variant_Gene_id_2'].astype(int)\n",
    "data['Variant_Gene_id_2'] = data['Variant_Gene_id_2'].astype(str)\n",
    "data['Disease_id'] = data['Disease_id'].astype(int)\n",
    "data['Disease_id'] = data['Disease_id'].astype(str)\n",
    "# fill missing age\n",
    "data['age'].fillna(data['age'].mean(), inplace=True)\n",
    "\n",
    "# fill missing race\n",
    "data['race'].fillna('unknown', inplace=True)\n",
    "\n",
    "# fill missing region\n",
    "data['region'].fillna('unknown', inplace=True)\n",
    "\n",
    "# fill missing gender\n",
    "data['gender'].fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select feature columns\n",
    "patient_information = ['gender', 'age', 'region', 'race']\n",
    "variant_information = ['Variant_Gene_id_1', 'Variant_Gene_id_2', 'Variant_Gene_chromosome_name_1', 'Variant_Gene_chromosome_name_2', 'Variant_Gene_chromosome_location_1', 'Variant_Gene_chromosome_location_2', \n",
    "'Variant_Gene_exon_count_1', 'Variant_Gene_exon_count_2']\n",
    "phenotype_information = [col for col in data.columns if col.startswith('HP')]\n",
    "\n",
    "features = []\n",
    "features = features + patient_information \n",
    "features = features + variant_information\n",
    "features = features + phenotype_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous variables shape:  torch.Size([689, 3])\n",
      "Categorical variables:  torch.Size([689, 999])\n",
      "All variables shape:  torch.Size([689, 1002])\n",
      "torch.Size([482, 3]) torch.Size([482, 999]) torch.Size([482, 1002]) torch.Size([482])\n",
      "torch.Size([207, 3]) torch.Size([207, 999]) torch.Size([207, 1002]) torch.Size([207])\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "scaler = StandardScaler()  \n",
    "cont_cols = ['age', 'Variant_Gene_exon_count_1', 'Variant_Gene_exon_count_2']\n",
    "cat_cols = [col for col in features if col not in cont_cols]\n",
    "\n",
    "# X_cont, X_cat are used in TabeTransformer and FTTransfromer, as these models require separation of continuous variables from categorical variables\n",
    "X_cont = data[cont_cols]\n",
    "X_cont = scaler.fit_transform(X_cont)\n",
    "X_cat = pd.get_dummies(data[cat_cols], prefix=None, prefix_sep='_').values \n",
    "\n",
    "X = pd.get_dummies(data[features], prefix=None, prefix_sep='_')\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "y = data['Disease_id']\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)  \n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "X_cont_tensor = torch.tensor(X_cont, dtype=torch.float32)\n",
    "X_cat_tensor = torch.tensor(X_cat, dtype=torch.long)\n",
    "\n",
    "\n",
    "# split\n",
    "indices = np.arange(len(X))\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.3, random_state=5)\n",
    "X_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(X_tensor, y_tensor, test_size=0.3, random_state=5) \n",
    "X_cont_train, X_cont_test = X_cont_tensor[train_idx], X_cont_tensor[test_idx]\n",
    "X_cat_train, X_cat_test = X_cat_tensor[train_idx], X_cat_tensor[test_idx]\n",
    "\n",
    "print(\"Continuous variables shape: \", X_cont_tensor.shape)\n",
    "print(\"Categorical variables: \", X_cat_tensor.shape)\n",
    "print(\"All variables shape: \", X_tensor.shape)\n",
    "print(X_cont_train.shape, X_cat_train.shape, X_train_nn.shape, y_train_nn.shape)\n",
    "print(X_cont_test.shape, X_cat_test.shape, X_test_nn.shape, y_test_nn.shape)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------ DL methods ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300], Loss: 0.5892\n",
      "MLP F1 score macro: 0.5152\n",
      "MLP Test Accuracy: 0.7681159420289855\n",
      "Epoch [20/300], Loss: 0.0023\n",
      "MLP F1 score macro: 0.5309\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [30/300], Loss: 0.0029\n",
      "MLP F1 score macro: 0.5347\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [40/300], Loss: 0.0009\n",
      "MLP F1 score macro: 0.5338\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [50/300], Loss: 0.0001\n",
      "MLP F1 score macro: 0.5338\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [60/300], Loss: 0.0001\n",
      "MLP F1 score macro: 0.5338\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [70/300], Loss: 0.0003\n",
      "MLP F1 score macro: 0.5338\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [80/300], Loss: 0.0001\n",
      "MLP F1 score macro: 0.5338\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [90/300], Loss: 0.0006\n",
      "MLP F1 score macro: 0.5346\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [100/300], Loss: 0.0000\n",
      "MLP F1 score macro: 0.5346\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [110/300], Loss: 0.0001\n",
      "MLP F1 score macro: 0.5346\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [120/300], Loss: 0.0000\n",
      "MLP F1 score macro: 0.5390\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [130/300], Loss: 0.0001\n",
      "MLP F1 score macro: 0.5390\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [140/300], Loss: 0.0000\n",
      "MLP F1 score macro: 0.5355\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [150/300], Loss: 0.0001\n",
      "MLP F1 score macro: 0.5395\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [160/300], Loss: 0.0000\n",
      "MLP F1 score macro: 0.5386\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [170/300], Loss: 0.0000\n",
      "MLP F1 score macro: 0.5386\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [180/300], Loss: 0.0001\n",
      "MLP F1 score macro: 0.5431\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [190/300], Loss: 0.0000\n",
      "MLP F1 score macro: 0.5431\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [200/300], Loss: 0.0000\n",
      "MLP F1 score macro: 0.5431\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [210/300], Loss: 0.0002\n",
      "MLP F1 score macro: 0.5431\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [220/300], Loss: 0.0000\n",
      "MLP F1 score macro: 0.5431\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [230/300], Loss: 0.0000\n",
      "MLP F1 score macro: 0.5476\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [240/300], Loss: 0.0000\n",
      "MLP F1 score macro: 0.5476\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [250/300], Loss: 0.0000\n",
      "MLP F1 score macro: 0.5476\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [260/300], Loss: 0.0000\n",
      "MLP F1 score macro: 0.5476\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [270/300], Loss: 0.0000\n",
      "MLP F1 score macro: 0.5476\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [280/300], Loss: 0.0000\n",
      "MLP F1 score macro: 0.5476\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [290/300], Loss: 0.0000\n",
      "MLP F1 score macro: 0.5476\n",
      "MLP Test Accuracy: 0.7874396135265701\n",
      "Epoch [300/300], Loss: 0.0000\n",
      "MLP F1 score macro: 0.5476\n",
      "MLP Test Accuracy: 0.7874396135265701\n"
     ]
    }
   ],
   "source": [
    "# ============== MLP ==============\n",
    "class TableDataClassifier(nn.Module):  \n",
    "    def __init__(self, input_dim, output_dim):  \n",
    "        super(TableDataClassifier, self).__init__()  \n",
    "        self.fc1 = nn.Linear(input_dim, 512)  \n",
    "        self.relu = nn.ReLU()  \n",
    "        self.dropout = nn.Dropout(0.5)  \n",
    "        self.fc2 = nn.Linear(512, 256)  \n",
    "        self.fc3 = nn.Linear(256, output_dim)  \n",
    "          \n",
    "    def forward(self, x):  \n",
    "        x = self.fc1(x)  \n",
    "        x = self.relu(x)  \n",
    "        x = self.dropout(x)  \n",
    "        x = self.fc2(x)  \n",
    "        x = self.relu(x)  \n",
    "        x = self.dropout(x)  \n",
    "        x = self.fc3(x)  \n",
    "        return x  \n",
    "\n",
    "\n",
    "# model\n",
    "MLP = TableDataClassifier(X_train_nn.shape[1], 211)\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(MLP.parameters(), lr=0.001)  \n",
    "\n",
    "num_epochs = 300\n",
    "batch_size = 32  \n",
    "train_dataset = TensorDataset(X_train_nn, y_train_nn)  \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# train\n",
    "MLP.train()  \n",
    "for epoch in range(num_epochs):  \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):  \n",
    "        optimizer.zero_grad()  \n",
    "        output = MLP(data)  \n",
    "        loss = criterion(output, target)  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "    if (epoch+1) % 10 == 0:  \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')  \n",
    "\n",
    "        # eval\n",
    "        MLP.eval()  \n",
    "        with torch.no_grad():  \n",
    "            X_test_nn = X_test_nn\n",
    "            y_pred_nn = MLP(X_test_nn).argmax(dim=1)  \n",
    "            f1_macro_nn = f1_score(y_test_nn, y_pred_nn, average='macro')\n",
    "            print(f'MLP F1 score macro: {f1_macro_nn:.4f}') \n",
    "            print('MLP Test Accuracy:', accuracy_score(y_test_nn, y_pred_nn))\n",
    "    \n",
    "# ============== MLP =============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/800], Loss: 5.1148\n",
      "TabNet F1 score macro: 0.0003\n",
      "TabNet Test Accuracy: 0.014492753623188406\n",
      "Epoch [20/800], Loss: 4.5467\n",
      "TabNet F1 score macro: 0.0020\n",
      "TabNet Test Accuracy: 0.05314009661835749\n",
      "Epoch [30/800], Loss: 4.0606\n",
      "TabNet F1 score macro: 0.0314\n",
      "TabNet Test Accuracy: 0.10144927536231885\n",
      "Epoch [40/800], Loss: 3.2806\n",
      "TabNet F1 score macro: 0.0760\n",
      "TabNet Test Accuracy: 0.24154589371980675\n",
      "Epoch [50/800], Loss: 2.4693\n",
      "TabNet F1 score macro: 0.0869\n",
      "TabNet Test Accuracy: 0.24154589371980675\n",
      "Epoch [60/800], Loss: 2.0482\n",
      "TabNet F1 score macro: 0.1353\n",
      "TabNet Test Accuracy: 0.34299516908212563\n",
      "Epoch [70/800], Loss: 1.7213\n",
      "TabNet F1 score macro: 0.1528\n",
      "TabNet Test Accuracy: 0.391304347826087\n",
      "Epoch [80/800], Loss: 1.6021\n",
      "TabNet F1 score macro: 0.1934\n",
      "TabNet Test Accuracy: 0.43478260869565216\n",
      "Epoch [90/800], Loss: 1.1583\n",
      "TabNet F1 score macro: 0.2133\n",
      "TabNet Test Accuracy: 0.42995169082125606\n",
      "Epoch [100/800], Loss: 0.9745\n",
      "TabNet F1 score macro: 0.2009\n",
      "TabNet Test Accuracy: 0.4396135265700483\n",
      "Epoch [110/800], Loss: 1.2463\n",
      "TabNet F1 score macro: 0.2012\n",
      "TabNet Test Accuracy: 0.45893719806763283\n",
      "Epoch [120/800], Loss: 0.8487\n",
      "TabNet F1 score macro: 0.2287\n",
      "TabNet Test Accuracy: 0.47342995169082125\n",
      "Epoch [130/800], Loss: 0.7400\n",
      "TabNet F1 score macro: 0.2455\n",
      "TabNet Test Accuracy: 0.4830917874396135\n",
      "Epoch [140/800], Loss: 0.7658\n",
      "TabNet F1 score macro: 0.2375\n",
      "TabNet Test Accuracy: 0.4927536231884058\n",
      "Epoch [150/800], Loss: 0.5137\n",
      "TabNet F1 score macro: 0.2504\n",
      "TabNet Test Accuracy: 0.5169082125603864\n",
      "Epoch [160/800], Loss: 0.7452\n",
      "TabNet F1 score macro: 0.2399\n",
      "TabNet Test Accuracy: 0.4927536231884058\n",
      "Epoch [170/800], Loss: 0.4321\n",
      "TabNet F1 score macro: 0.2605\n",
      "TabNet Test Accuracy: 0.5169082125603864\n",
      "Epoch [180/800], Loss: 0.5247\n",
      "TabNet F1 score macro: 0.2693\n",
      "TabNet Test Accuracy: 0.5265700483091788\n",
      "Epoch [190/800], Loss: 0.3941\n",
      "TabNet F1 score macro: 0.2606\n",
      "TabNet Test Accuracy: 0.5314009661835749\n",
      "Epoch [200/800], Loss: 0.4294\n",
      "TabNet F1 score macro: 0.2272\n",
      "TabNet Test Accuracy: 0.5072463768115942\n",
      "Epoch [210/800], Loss: 0.4127\n",
      "TabNet F1 score macro: 0.2629\n",
      "TabNet Test Accuracy: 0.5169082125603864\n",
      "Epoch [220/800], Loss: 0.3325\n",
      "TabNet F1 score macro: 0.2719\n",
      "TabNet Test Accuracy: 0.5362318840579711\n",
      "Epoch [230/800], Loss: 0.3256\n",
      "TabNet F1 score macro: 0.2818\n",
      "TabNet Test Accuracy: 0.5314009661835749\n",
      "Epoch [240/800], Loss: 0.3294\n",
      "TabNet F1 score macro: 0.2438\n",
      "TabNet Test Accuracy: 0.5314009661835749\n",
      "Epoch [250/800], Loss: 0.2099\n",
      "TabNet F1 score macro: 0.2827\n",
      "TabNet Test Accuracy: 0.5507246376811594\n",
      "Epoch [260/800], Loss: 0.2032\n",
      "TabNet F1 score macro: 0.2856\n",
      "TabNet Test Accuracy: 0.5458937198067633\n",
      "Epoch [270/800], Loss: 0.5049\n",
      "TabNet F1 score macro: 0.2431\n",
      "TabNet Test Accuracy: 0.4830917874396135\n",
      "Epoch [280/800], Loss: 0.4096\n",
      "TabNet F1 score macro: 0.3198\n",
      "TabNet Test Accuracy: 0.5652173913043478\n",
      "Epoch [290/800], Loss: 0.2851\n",
      "TabNet F1 score macro: 0.2891\n",
      "TabNet Test Accuracy: 0.5507246376811594\n",
      "Epoch [300/800], Loss: 0.2469\n",
      "TabNet F1 score macro: 0.2926\n",
      "TabNet Test Accuracy: 0.5507246376811594\n",
      "Epoch [310/800], Loss: 0.2519\n",
      "TabNet F1 score macro: 0.2969\n",
      "TabNet Test Accuracy: 0.5555555555555556\n",
      "Epoch [320/800], Loss: 0.1753\n",
      "TabNet F1 score macro: 0.3191\n",
      "TabNet Test Accuracy: 0.5603864734299517\n",
      "Epoch [330/800], Loss: 0.1992\n",
      "TabNet F1 score macro: 0.2833\n",
      "TabNet Test Accuracy: 0.5410628019323671\n",
      "Epoch [340/800], Loss: 0.1940\n",
      "TabNet F1 score macro: 0.2954\n",
      "TabNet Test Accuracy: 0.5603864734299517\n",
      "Epoch [350/800], Loss: 0.1716\n",
      "TabNet F1 score macro: 0.2687\n",
      "TabNet Test Accuracy: 0.5410628019323671\n",
      "Epoch [360/800], Loss: 0.2647\n",
      "TabNet F1 score macro: 0.2917\n",
      "TabNet Test Accuracy: 0.5458937198067633\n",
      "Epoch [370/800], Loss: 0.4584\n",
      "TabNet F1 score macro: 0.2930\n",
      "TabNet Test Accuracy: 0.5507246376811594\n",
      "Epoch [380/800], Loss: 0.2414\n",
      "TabNet F1 score macro: 0.3058\n",
      "TabNet Test Accuracy: 0.5652173913043478\n",
      "Epoch [390/800], Loss: 0.0804\n",
      "TabNet F1 score macro: 0.3232\n",
      "TabNet Test Accuracy: 0.5700483091787439\n",
      "Epoch [400/800], Loss: 0.1455\n",
      "TabNet F1 score macro: 0.3255\n",
      "TabNet Test Accuracy: 0.5700483091787439\n",
      "Epoch [410/800], Loss: 0.1758\n",
      "TabNet F1 score macro: 0.2951\n",
      "TabNet Test Accuracy: 0.5603864734299517\n",
      "Epoch [420/800], Loss: 0.1499\n",
      "TabNet F1 score macro: 0.3485\n",
      "TabNet Test Accuracy: 0.5845410628019324\n",
      "Epoch [430/800], Loss: 0.1526\n",
      "TabNet F1 score macro: 0.3243\n",
      "TabNet Test Accuracy: 0.5797101449275363\n",
      "Epoch [440/800], Loss: 0.1768\n",
      "TabNet F1 score macro: 0.3133\n",
      "TabNet Test Accuracy: 0.5603864734299517\n",
      "Epoch [450/800], Loss: 0.1338\n",
      "TabNet F1 score macro: 0.3125\n",
      "TabNet Test Accuracy: 0.5652173913043478\n",
      "Epoch [460/800], Loss: 0.2885\n",
      "TabNet F1 score macro: 0.3029\n",
      "TabNet Test Accuracy: 0.5555555555555556\n",
      "Epoch [470/800], Loss: 0.5792\n",
      "TabNet F1 score macro: 0.3093\n",
      "TabNet Test Accuracy: 0.5700483091787439\n",
      "Epoch [480/800], Loss: 0.3626\n",
      "TabNet F1 score macro: 0.3130\n",
      "TabNet Test Accuracy: 0.5893719806763285\n",
      "Epoch [490/800], Loss: 0.1582\n",
      "TabNet F1 score macro: 0.3257\n",
      "TabNet Test Accuracy: 0.5845410628019324\n",
      "Epoch [500/800], Loss: 0.0885\n",
      "TabNet F1 score macro: 0.3157\n",
      "TabNet Test Accuracy: 0.5797101449275363\n",
      "Epoch [510/800], Loss: 0.0692\n",
      "TabNet F1 score macro: 0.3421\n",
      "TabNet Test Accuracy: 0.5893719806763285\n",
      "Epoch [520/800], Loss: 0.0653\n",
      "TabNet F1 score macro: 0.3417\n",
      "TabNet Test Accuracy: 0.5990338164251208\n",
      "Epoch [530/800], Loss: 0.0867\n",
      "TabNet F1 score macro: 0.3093\n",
      "TabNet Test Accuracy: 0.5748792270531401\n",
      "Epoch [540/800], Loss: 0.0569\n",
      "TabNet F1 score macro: 0.3453\n",
      "TabNet Test Accuracy: 0.5893719806763285\n",
      "Epoch [550/800], Loss: 0.2141\n",
      "TabNet F1 score macro: 0.3205\n",
      "TabNet Test Accuracy: 0.5845410628019324\n",
      "Epoch [560/800], Loss: 0.0636\n",
      "TabNet F1 score macro: 0.3384\n",
      "TabNet Test Accuracy: 0.5990338164251208\n",
      "Epoch [570/800], Loss: 0.4211\n",
      "TabNet F1 score macro: 0.3205\n",
      "TabNet Test Accuracy: 0.5893719806763285\n",
      "Epoch [580/800], Loss: 0.2506\n",
      "TabNet F1 score macro: 0.3360\n",
      "TabNet Test Accuracy: 0.5990338164251208\n",
      "Epoch [590/800], Loss: 0.1628\n",
      "TabNet F1 score macro: 0.3110\n",
      "TabNet Test Accuracy: 0.5797101449275363\n",
      "Epoch [600/800], Loss: 0.1444\n",
      "TabNet F1 score macro: 0.3304\n",
      "TabNet Test Accuracy: 0.5845410628019324\n",
      "Epoch [610/800], Loss: 0.5407\n",
      "TabNet F1 score macro: 0.2014\n",
      "TabNet Test Accuracy: 0.3671497584541063\n",
      "Epoch [620/800], Loss: 0.3943\n",
      "TabNet F1 score macro: 0.3108\n",
      "TabNet Test Accuracy: 0.5700483091787439\n",
      "Epoch [630/800], Loss: 0.1319\n",
      "TabNet F1 score macro: 0.3209\n",
      "TabNet Test Accuracy: 0.5893719806763285\n",
      "Epoch [640/800], Loss: 0.0707\n",
      "TabNet F1 score macro: 0.3314\n",
      "TabNet Test Accuracy: 0.5893719806763285\n",
      "Epoch [650/800], Loss: 0.0580\n",
      "TabNet F1 score macro: 0.3084\n",
      "TabNet Test Accuracy: 0.5845410628019324\n",
      "Epoch [660/800], Loss: 0.0719\n",
      "TabNet F1 score macro: 0.3588\n",
      "TabNet Test Accuracy: 0.5990338164251208\n",
      "Epoch [670/800], Loss: 0.1855\n",
      "TabNet F1 score macro: 0.3132\n",
      "TabNet Test Accuracy: 0.5845410628019324\n",
      "Epoch [680/800], Loss: 0.0794\n",
      "TabNet F1 score macro: 0.3341\n",
      "TabNet Test Accuracy: 0.5942028985507246\n",
      "Epoch [690/800], Loss: 0.0606\n",
      "TabNet F1 score macro: 0.3345\n",
      "TabNet Test Accuracy: 0.5942028985507246\n",
      "Epoch [700/800], Loss: 0.0612\n",
      "TabNet F1 score macro: 0.3506\n",
      "TabNet Test Accuracy: 0.5990338164251208\n",
      "Epoch [710/800], Loss: 0.0720\n",
      "TabNet F1 score macro: 0.3162\n",
      "TabNet Test Accuracy: 0.5845410628019324\n",
      "Epoch [720/800], Loss: 0.0363\n",
      "TabNet F1 score macro: 0.3274\n",
      "TabNet Test Accuracy: 0.5845410628019324\n",
      "Epoch [730/800], Loss: 0.0964\n",
      "TabNet F1 score macro: 0.3267\n",
      "TabNet Test Accuracy: 0.5797101449275363\n",
      "Epoch [740/800], Loss: 0.0759\n",
      "TabNet F1 score macro: 0.3598\n",
      "TabNet Test Accuracy: 0.6038647342995169\n",
      "Epoch [750/800], Loss: 0.0566\n",
      "TabNet F1 score macro: 0.3477\n",
      "TabNet Test Accuracy: 0.6038647342995169\n",
      "Epoch [760/800], Loss: 0.1150\n",
      "TabNet F1 score macro: 0.3380\n",
      "TabNet Test Accuracy: 0.5893719806763285\n",
      "Epoch [770/800], Loss: 0.1363\n",
      "TabNet F1 score macro: 0.3426\n",
      "TabNet Test Accuracy: 0.6086956521739131\n",
      "Epoch [780/800], Loss: 0.0396\n",
      "TabNet F1 score macro: 0.3305\n",
      "TabNet Test Accuracy: 0.6038647342995169\n",
      "Epoch [790/800], Loss: 0.0853\n",
      "TabNet F1 score macro: 0.3271\n",
      "TabNet Test Accuracy: 0.5990338164251208\n",
      "Epoch [800/800], Loss: 0.0353\n",
      "TabNet F1 score macro: 0.3487\n",
      "TabNet Test Accuracy: 0.6038647342995169\n"
     ]
    }
   ],
   "source": [
    "# ============== TabNet ==============\n",
    "# TabNet : Attentive Interpretable Tabular Learning\n",
    "input_dim = X_train_nn.shape[1]\n",
    "output_dim = 211\n",
    "group_matrix = create_group_matrix([], input_dim)\n",
    "model = tab_network.TabNet(input_dim=input_dim, output_dim=output_dim, group_attention_matrix=group_matrix)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=4e-2)  \n",
    "num_epochs = 800\n",
    "batch_size = 256\n",
    "lambda_sparse = 0.01\n",
    "train_dataset = TensorDataset(X_train_nn, y_train_nn)  \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# train\n",
    "for epoch in range(num_epochs):  \n",
    "    model.train()  \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):  \n",
    "        optimizer.zero_grad()  \n",
    "        output, M_loss = model(data)  \n",
    "        loss = criterion(output, target)\n",
    "        loss = loss - lambda_sparse * M_loss  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "    if (epoch+1) % 10 == 0:  \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')  \n",
    "\n",
    "        # eval\n",
    "        model.eval()  \n",
    "        with torch.no_grad():  \n",
    "            output, M_loss = model(X_test_nn)\n",
    "            y_pred_nn = output.argmax(dim=1)\n",
    "            f1_macro_nn = f1_score(y_test_nn, y_pred_nn, average='macro')\n",
    "            print(f'TabNet F1 score macro: {f1_macro_nn:.4f}') \n",
    "            print('TabNet Test Accuracy:', accuracy_score(y_test_nn, y_pred_nn))\n",
    "\n",
    "# ============== TabNet =============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 5.0539\n",
      "FTTransformer F1 score macro: 0.0001\n",
      "FTTransformer Test Accuracy: 0.004830917874396135\n",
      "Epoch [2/100], Loss: 5.1177\n",
      "FTTransformer F1 score macro: 0.0001\n",
      "FTTransformer Test Accuracy: 0.004830917874396135\n",
      "Epoch [3/100], Loss: 4.8917\n",
      "FTTransformer F1 score macro: 0.0001\n",
      "FTTransformer Test Accuracy: 0.004830917874396135\n",
      "Epoch [4/100], Loss: 5.1783\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [5/100], Loss: 5.0824\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [6/100], Loss: 4.8439\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [7/100], Loss: 5.0624\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [8/100], Loss: 4.7181\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [9/100], Loss: 4.8031\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [10/100], Loss: 4.6973\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [11/100], Loss: 5.0442\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [12/100], Loss: 4.9632\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [13/100], Loss: 4.8187\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [14/100], Loss: 4.6644\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [15/100], Loss: 4.8970\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [16/100], Loss: 4.6950\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [17/100], Loss: 4.6748\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [18/100], Loss: 4.7858\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [19/100], Loss: 4.6204\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [20/100], Loss: 4.7556\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [21/100], Loss: 4.4820\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [22/100], Loss: 4.9620\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [23/100], Loss: 4.6132\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [24/100], Loss: 4.7984\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [25/100], Loss: 4.5830\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [26/100], Loss: 4.6448\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [27/100], Loss: 4.7257\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [28/100], Loss: 4.8292\n",
      "FTTransformer F1 score macro: 0.0004\n",
      "FTTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [29/100], Loss: 4.6623\n",
      "FTTransformer F1 score macro: 0.0107\n",
      "FTTransformer Test Accuracy: 0.057971014492753624\n",
      "Epoch [30/100], Loss: 4.3793\n",
      "FTTransformer F1 score macro: 0.0365\n",
      "FTTransformer Test Accuracy: 0.1642512077294686\n",
      "Epoch [31/100], Loss: 4.3726\n",
      "FTTransformer F1 score macro: 0.0472\n",
      "FTTransformer Test Accuracy: 0.21256038647342995\n",
      "Epoch [32/100], Loss: 4.3011\n",
      "FTTransformer F1 score macro: 0.0510\n",
      "FTTransformer Test Accuracy: 0.2028985507246377\n",
      "Epoch [33/100], Loss: 4.4353\n",
      "FTTransformer F1 score macro: 0.0624\n",
      "FTTransformer Test Accuracy: 0.25120772946859904\n",
      "Epoch [34/100], Loss: 3.9192\n",
      "FTTransformer F1 score macro: 0.0779\n",
      "FTTransformer Test Accuracy: 0.30434782608695654\n",
      "Epoch [35/100], Loss: 3.6649\n",
      "FTTransformer F1 score macro: 0.1237\n",
      "FTTransformer Test Accuracy: 0.357487922705314\n",
      "Epoch [36/100], Loss: 3.9826\n",
      "FTTransformer F1 score macro: 0.1756\n",
      "FTTransformer Test Accuracy: 0.45410628019323673\n",
      "Epoch [37/100], Loss: 3.1343\n",
      "FTTransformer F1 score macro: 0.2115\n",
      "FTTransformer Test Accuracy: 0.4782608695652174\n",
      "Epoch [38/100], Loss: 3.2518\n",
      "FTTransformer F1 score macro: 0.1988\n",
      "FTTransformer Test Accuracy: 0.4782608695652174\n",
      "Epoch [39/100], Loss: 3.0486\n",
      "FTTransformer F1 score macro: 0.2170\n",
      "FTTransformer Test Accuracy: 0.5120772946859904\n",
      "Epoch [40/100], Loss: 3.5545\n",
      "FTTransformer F1 score macro: 0.2259\n",
      "FTTransformer Test Accuracy: 0.5265700483091788\n",
      "Epoch [41/100], Loss: 2.9317\n",
      "FTTransformer F1 score macro: 0.2493\n",
      "FTTransformer Test Accuracy: 0.5458937198067633\n",
      "Epoch [42/100], Loss: 2.6623\n",
      "FTTransformer F1 score macro: 0.2565\n",
      "FTTransformer Test Accuracy: 0.5555555555555556\n",
      "Epoch [43/100], Loss: 2.4404\n",
      "FTTransformer F1 score macro: 0.2735\n",
      "FTTransformer Test Accuracy: 0.5652173913043478\n",
      "Epoch [44/100], Loss: 2.7059\n",
      "FTTransformer F1 score macro: 0.2924\n",
      "FTTransformer Test Accuracy: 0.6038647342995169\n",
      "Epoch [45/100], Loss: 2.6048\n",
      "FTTransformer F1 score macro: 0.3114\n",
      "FTTransformer Test Accuracy: 0.6231884057971014\n",
      "Epoch [46/100], Loss: 1.9443\n",
      "FTTransformer F1 score macro: 0.3171\n",
      "FTTransformer Test Accuracy: 0.6280193236714976\n",
      "Epoch [47/100], Loss: 1.7806\n",
      "FTTransformer F1 score macro: 0.3446\n",
      "FTTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [48/100], Loss: 2.3170\n",
      "FTTransformer F1 score macro: 0.3712\n",
      "FTTransformer Test Accuracy: 0.6618357487922706\n",
      "Epoch [49/100], Loss: 1.6734\n",
      "FTTransformer F1 score macro: 0.3543\n",
      "FTTransformer Test Accuracy: 0.6521739130434783\n",
      "Epoch [50/100], Loss: 1.3454\n",
      "FTTransformer F1 score macro: 0.3599\n",
      "FTTransformer Test Accuracy: 0.6521739130434783\n",
      "Epoch [51/100], Loss: 1.3844\n",
      "FTTransformer F1 score macro: 0.3877\n",
      "FTTransformer Test Accuracy: 0.6763285024154589\n",
      "Epoch [52/100], Loss: 1.5955\n",
      "FTTransformer F1 score macro: 0.3902\n",
      "FTTransformer Test Accuracy: 0.6811594202898551\n",
      "Epoch [53/100], Loss: 1.3222\n",
      "FTTransformer F1 score macro: 0.3983\n",
      "FTTransformer Test Accuracy: 0.6859903381642513\n",
      "Epoch [54/100], Loss: 0.9386\n",
      "FTTransformer F1 score macro: 0.4287\n",
      "FTTransformer Test Accuracy: 0.7004830917874396\n",
      "Epoch [55/100], Loss: 1.4390\n",
      "FTTransformer F1 score macro: 0.4203\n",
      "FTTransformer Test Accuracy: 0.7004830917874396\n",
      "Epoch [56/100], Loss: 1.3063\n",
      "FTTransformer F1 score macro: 0.4204\n",
      "FTTransformer Test Accuracy: 0.6956521739130435\n",
      "Epoch [57/100], Loss: 1.1792\n",
      "FTTransformer F1 score macro: 0.4384\n",
      "FTTransformer Test Accuracy: 0.7101449275362319\n",
      "Epoch [58/100], Loss: 1.2725\n",
      "FTTransformer F1 score macro: 0.4398\n",
      "FTTransformer Test Accuracy: 0.7101449275362319\n",
      "Epoch [59/100], Loss: 1.2910\n",
      "FTTransformer F1 score macro: 0.4651\n",
      "FTTransformer Test Accuracy: 0.7342995169082126\n",
      "Epoch [60/100], Loss: 0.9522\n",
      "FTTransformer F1 score macro: 0.4863\n",
      "FTTransformer Test Accuracy: 0.7536231884057971\n",
      "Epoch [61/100], Loss: 0.9753\n",
      "FTTransformer F1 score macro: 0.5095\n",
      "FTTransformer Test Accuracy: 0.7536231884057971\n",
      "Epoch [62/100], Loss: 0.9807\n",
      "FTTransformer F1 score macro: 0.5035\n",
      "FTTransformer Test Accuracy: 0.7632850241545893\n",
      "Epoch [63/100], Loss: 0.8142\n",
      "FTTransformer F1 score macro: 0.5078\n",
      "FTTransformer Test Accuracy: 0.7632850241545893\n",
      "Epoch [64/100], Loss: 0.5720\n",
      "FTTransformer F1 score macro: 0.4930\n",
      "FTTransformer Test Accuracy: 0.7584541062801933\n",
      "Epoch [65/100], Loss: 0.8270\n",
      "FTTransformer F1 score macro: 0.5092\n",
      "FTTransformer Test Accuracy: 0.7681159420289855\n",
      "Epoch [66/100], Loss: 0.6577\n",
      "FTTransformer F1 score macro: 0.5147\n",
      "FTTransformer Test Accuracy: 0.7681159420289855\n",
      "Epoch [67/100], Loss: 0.7506\n",
      "FTTransformer F1 score macro: 0.5105\n",
      "FTTransformer Test Accuracy: 0.7681159420289855\n",
      "Epoch [68/100], Loss: 0.6146\n",
      "FTTransformer F1 score macro: 0.5146\n",
      "FTTransformer Test Accuracy: 0.7777777777777778\n",
      "Epoch [69/100], Loss: 0.7176\n",
      "FTTransformer F1 score macro: 0.5117\n",
      "FTTransformer Test Accuracy: 0.7777777777777778\n",
      "Epoch [70/100], Loss: 0.5893\n",
      "FTTransformer F1 score macro: 0.5130\n",
      "FTTransformer Test Accuracy: 0.782608695652174\n",
      "Epoch [71/100], Loss: 0.5103\n",
      "FTTransformer F1 score macro: 0.5155\n",
      "FTTransformer Test Accuracy: 0.782608695652174\n",
      "Epoch [72/100], Loss: 0.6308\n",
      "FTTransformer F1 score macro: 0.5467\n",
      "FTTransformer Test Accuracy: 0.8019323671497585\n",
      "Epoch [73/100], Loss: 0.4277\n",
      "FTTransformer F1 score macro: 0.5464\n",
      "FTTransformer Test Accuracy: 0.7971014492753623\n",
      "Epoch [74/100], Loss: 0.4276\n",
      "FTTransformer F1 score macro: 0.5380\n",
      "FTTransformer Test Accuracy: 0.7922705314009661\n",
      "Epoch [75/100], Loss: 0.4479\n",
      "FTTransformer F1 score macro: 0.5339\n",
      "FTTransformer Test Accuracy: 0.7922705314009661\n",
      "Epoch [76/100], Loss: 0.6218\n",
      "FTTransformer F1 score macro: 0.5358\n",
      "FTTransformer Test Accuracy: 0.7922705314009661\n",
      "Epoch [77/100], Loss: 0.5710\n",
      "FTTransformer F1 score macro: 0.5407\n",
      "FTTransformer Test Accuracy: 0.7922705314009661\n",
      "Epoch [78/100], Loss: 0.4132\n",
      "FTTransformer F1 score macro: 0.5528\n",
      "FTTransformer Test Accuracy: 0.7971014492753623\n",
      "Epoch [79/100], Loss: 0.3991\n",
      "FTTransformer F1 score macro: 0.5443\n",
      "FTTransformer Test Accuracy: 0.7971014492753623\n",
      "Epoch [80/100], Loss: 0.4246\n",
      "FTTransformer F1 score macro: 0.5409\n",
      "FTTransformer Test Accuracy: 0.7971014492753623\n",
      "Epoch [81/100], Loss: 0.2818\n",
      "FTTransformer F1 score macro: 0.5345\n",
      "FTTransformer Test Accuracy: 0.782608695652174\n",
      "Epoch [82/100], Loss: 0.4481\n",
      "FTTransformer F1 score macro: 0.5307\n",
      "FTTransformer Test Accuracy: 0.782608695652174\n",
      "Epoch [83/100], Loss: 0.3021\n",
      "FTTransformer F1 score macro: 0.5307\n",
      "FTTransformer Test Accuracy: 0.7874396135265701\n",
      "Epoch [84/100], Loss: 0.5098\n",
      "FTTransformer F1 score macro: 0.5347\n",
      "FTTransformer Test Accuracy: 0.7874396135265701\n",
      "Epoch [85/100], Loss: 0.3901\n",
      "FTTransformer F1 score macro: 0.5226\n",
      "FTTransformer Test Accuracy: 0.7874396135265701\n",
      "Epoch [86/100], Loss: 0.2560\n",
      "FTTransformer F1 score macro: 0.5238\n",
      "FTTransformer Test Accuracy: 0.7874396135265701\n",
      "Epoch [87/100], Loss: 0.3484\n",
      "FTTransformer F1 score macro: 0.5430\n",
      "FTTransformer Test Accuracy: 0.7922705314009661\n",
      "Epoch [88/100], Loss: 0.2200\n",
      "FTTransformer F1 score macro: 0.5258\n",
      "FTTransformer Test Accuracy: 0.7874396135265701\n",
      "Epoch [89/100], Loss: 0.3550\n",
      "FTTransformer F1 score macro: 0.5199\n",
      "FTTransformer Test Accuracy: 0.7874396135265701\n",
      "Epoch [90/100], Loss: 0.2185\n",
      "FTTransformer F1 score macro: 0.5173\n",
      "FTTransformer Test Accuracy: 0.7874396135265701\n",
      "Epoch [91/100], Loss: 0.3134\n",
      "FTTransformer F1 score macro: 0.5311\n",
      "FTTransformer Test Accuracy: 0.7922705314009661\n",
      "Epoch [92/100], Loss: 0.1894\n",
      "FTTransformer F1 score macro: 0.5350\n",
      "FTTransformer Test Accuracy: 0.7922705314009661\n",
      "Epoch [93/100], Loss: 0.2220\n",
      "FTTransformer F1 score macro: 0.5359\n",
      "FTTransformer Test Accuracy: 0.7922705314009661\n",
      "Epoch [94/100], Loss: 0.2420\n",
      "FTTransformer F1 score macro: 0.5299\n",
      "FTTransformer Test Accuracy: 0.7922705314009661\n",
      "Epoch [95/100], Loss: 0.2489\n",
      "FTTransformer F1 score macro: 0.5347\n",
      "FTTransformer Test Accuracy: 0.7971014492753623\n",
      "Epoch [96/100], Loss: 0.3211\n",
      "FTTransformer F1 score macro: 0.5367\n",
      "FTTransformer Test Accuracy: 0.7971014492753623\n",
      "Epoch [97/100], Loss: 0.2048\n",
      "FTTransformer F1 score macro: 0.5291\n",
      "FTTransformer Test Accuracy: 0.7874396135265701\n",
      "Epoch [98/100], Loss: 0.1891\n",
      "FTTransformer F1 score macro: 0.5268\n",
      "FTTransformer Test Accuracy: 0.7874396135265701\n",
      "Epoch [99/100], Loss: 0.2576\n",
      "FTTransformer F1 score macro: 0.5307\n",
      "FTTransformer Test Accuracy: 0.7922705314009661\n",
      "Epoch [100/100], Loss: 0.2169\n",
      "FTTransformer F1 score macro: 0.5205\n",
      "FTTransformer Test Accuracy: 0.7922705314009661\n"
     ]
    }
   ],
   "source": [
    "# ============== FTTransformer ==============\n",
    "# Revisiting Deep Learning Models for Tabular Data\n",
    "output_dim = 211\n",
    "cat_cardinalities = [len(torch.unique(X_cat_tensor[:, i])) for i in range(X_cat_tensor.shape[1])]\n",
    "\n",
    "model = FTTransformer(\n",
    "    n_cont_features = len(cont_cols),\n",
    "    cat_cardinalities = cat_cardinalities,\n",
    "    d_out = output_dim,\n",
    "    **FTTransformer.get_default_kwargs(),\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)  \n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = TensorDataset(X_cat_train, X_cont_train, y_train_nn)\n",
    "test_dataset = TensorDataset(X_cat_test, X_cont_test, y_test_nn)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# train\n",
    "for epoch in range(num_epochs):  \n",
    "    model.train()  \n",
    "    optimizer.zero_grad()\n",
    "    for batch_idx, (X_cat, X_cont, y) in enumerate(train_loader):  \n",
    "        X_cat = X_cat.to(device)\n",
    "        X_cont = X_cont.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(X_cont, X_cat)  \n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "    if (epoch+1) % 1 == 0:  \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')  \n",
    "\n",
    "        # eval\n",
    "        model.eval()\n",
    "        all_preds = []  \n",
    "        with torch.no_grad():  \n",
    "            for X_cat, X_cont, y in test_loader:\n",
    "                X_cat = X_cat.to(device)\n",
    "                X_cont = X_cont.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                output = model(X_cont, X_cat)\n",
    "                preds = output.argmax(dim=1)\n",
    "                all_preds.append(preds)\n",
    "        y_pred_nn = torch.cat(all_preds, dim=0).cpu()\n",
    "        f1_macro_nn = f1_score(y_test_nn, y_pred_nn, average='macro')\n",
    "        print(f'FTTransformer F1 score macro: {f1_macro_nn:.4f}') \n",
    "        print('FTTransformer Test Accuracy:', accuracy_score(y_test_nn, y_pred_nn))\n",
    "# ============== FT Transformer =============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 6.4211\n",
      "TabTransformer F1 score macro: 0.0133\n",
      "TabTransformer Test Accuracy: 0.04830917874396135\n",
      "Epoch [2/300], Loss: 9.6264\n",
      "TabTransformer F1 score macro: 0.0004\n",
      "TabTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [3/300], Loss: 5.6955\n",
      "TabTransformer F1 score macro: 0.0005\n",
      "TabTransformer Test Accuracy: 0.028985507246376812\n",
      "Epoch [4/300], Loss: 6.5320\n",
      "TabTransformer F1 score macro: 0.0003\n",
      "TabTransformer Test Accuracy: 0.014492753623188406\n",
      "Epoch [5/300], Loss: 6.7467\n",
      "TabTransformer F1 score macro: 0.0004\n",
      "TabTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [6/300], Loss: 5.7163\n",
      "TabTransformer F1 score macro: 0.0007\n",
      "TabTransformer Test Accuracy: 0.03864734299516908\n",
      "Epoch [7/300], Loss: 3.1973\n",
      "TabTransformer F1 score macro: 0.0068\n",
      "TabTransformer Test Accuracy: 0.033816425120772944\n",
      "Epoch [8/300], Loss: 4.5461\n",
      "TabTransformer F1 score macro: 0.0131\n",
      "TabTransformer Test Accuracy: 0.04830917874396135\n",
      "Epoch [9/300], Loss: 6.4393\n",
      "TabTransformer F1 score macro: 0.0141\n",
      "TabTransformer Test Accuracy: 0.06280193236714976\n",
      "Epoch [10/300], Loss: 4.5894\n",
      "TabTransformer F1 score macro: 0.0005\n",
      "TabTransformer Test Accuracy: 0.028985507246376812\n",
      "Epoch [11/300], Loss: 3.7186\n",
      "TabTransformer F1 score macro: 0.0005\n",
      "TabTransformer Test Accuracy: 0.024154589371980676\n",
      "Epoch [12/300], Loss: 6.8335\n",
      "TabTransformer F1 score macro: 0.0104\n",
      "TabTransformer Test Accuracy: 0.07246376811594203\n",
      "Epoch [13/300], Loss: 4.7473\n",
      "TabTransformer F1 score macro: 0.0100\n",
      "TabTransformer Test Accuracy: 0.04830917874396135\n",
      "Epoch [14/300], Loss: 5.3716\n",
      "TabTransformer F1 score macro: 0.0149\n",
      "TabTransformer Test Accuracy: 0.057971014492753624\n",
      "Epoch [15/300], Loss: 5.8557\n",
      "TabTransformer F1 score macro: 0.0100\n",
      "TabTransformer Test Accuracy: 0.04830917874396135\n",
      "Epoch [16/300], Loss: 4.3299\n",
      "TabTransformer F1 score macro: 0.0005\n",
      "TabTransformer Test Accuracy: 0.028985507246376812\n",
      "Epoch [17/300], Loss: 4.7336\n",
      "TabTransformer F1 score macro: 0.0169\n",
      "TabTransformer Test Accuracy: 0.057971014492753624\n",
      "Epoch [18/300], Loss: 4.7665\n",
      "TabTransformer F1 score macro: 0.0005\n",
      "TabTransformer Test Accuracy: 0.028985507246376812\n",
      "Epoch [19/300], Loss: 5.3924\n",
      "TabTransformer F1 score macro: 0.0052\n",
      "TabTransformer Test Accuracy: 0.024154589371980676\n",
      "Epoch [20/300], Loss: 6.4912\n",
      "TabTransformer F1 score macro: 0.0004\n",
      "TabTransformer Test Accuracy: 0.01932367149758454\n",
      "Epoch [21/300], Loss: 3.6929\n",
      "TabTransformer F1 score macro: 0.0301\n",
      "TabTransformer Test Accuracy: 0.11594202898550725\n",
      "Epoch [22/300], Loss: 3.4585\n",
      "TabTransformer F1 score macro: 0.0123\n",
      "TabTransformer Test Accuracy: 0.0821256038647343\n",
      "Epoch [23/300], Loss: 3.3339\n",
      "TabTransformer F1 score macro: 0.0243\n",
      "TabTransformer Test Accuracy: 0.08695652173913043\n",
      "Epoch [24/300], Loss: 5.1835\n",
      "TabTransformer F1 score macro: 0.0005\n",
      "TabTransformer Test Accuracy: 0.024154589371980676\n",
      "Epoch [25/300], Loss: 4.3980\n",
      "TabTransformer F1 score macro: 0.0159\n",
      "TabTransformer Test Accuracy: 0.06763285024154589\n",
      "Epoch [26/300], Loss: 5.2639\n",
      "TabTransformer F1 score macro: 0.0119\n",
      "TabTransformer Test Accuracy: 0.08695652173913043\n",
      "Epoch [27/300], Loss: 6.0596\n",
      "TabTransformer F1 score macro: 0.0101\n",
      "TabTransformer Test Accuracy: 0.05314009661835749\n",
      "Epoch [28/300], Loss: 3.6444\n",
      "TabTransformer F1 score macro: 0.0069\n",
      "TabTransformer Test Accuracy: 0.057971014492753624\n",
      "Epoch [29/300], Loss: 4.9866\n",
      "TabTransformer F1 score macro: 0.0300\n",
      "TabTransformer Test Accuracy: 0.13043478260869565\n",
      "Epoch [30/300], Loss: 4.8699\n",
      "TabTransformer F1 score macro: 0.0172\n",
      "TabTransformer Test Accuracy: 0.07246376811594203\n",
      "Epoch [31/300], Loss: 4.1422\n",
      "TabTransformer F1 score macro: 0.0187\n",
      "TabTransformer Test Accuracy: 0.057971014492753624\n",
      "Epoch [32/300], Loss: 4.6927\n",
      "TabTransformer F1 score macro: 0.0053\n",
      "TabTransformer Test Accuracy: 0.028985507246376812\n",
      "Epoch [33/300], Loss: 5.3617\n",
      "TabTransformer F1 score macro: 0.0244\n",
      "TabTransformer Test Accuracy: 0.07729468599033816\n",
      "Epoch [34/300], Loss: 5.5281\n",
      "TabTransformer F1 score macro: 0.0334\n",
      "TabTransformer Test Accuracy: 0.10628019323671498\n",
      "Epoch [35/300], Loss: 4.7681\n",
      "TabTransformer F1 score macro: 0.0421\n",
      "TabTransformer Test Accuracy: 0.13043478260869565\n",
      "Epoch [36/300], Loss: 6.3297\n",
      "TabTransformer F1 score macro: 0.0233\n",
      "TabTransformer Test Accuracy: 0.06763285024154589\n",
      "Epoch [37/300], Loss: 5.2469\n",
      "TabTransformer F1 score macro: 0.0153\n",
      "TabTransformer Test Accuracy: 0.057971014492753624\n",
      "Epoch [38/300], Loss: 4.5663\n",
      "TabTransformer F1 score macro: 0.0114\n",
      "TabTransformer Test Accuracy: 0.06280193236714976\n",
      "Epoch [39/300], Loss: 4.5870\n",
      "TabTransformer F1 score macro: 0.0183\n",
      "TabTransformer Test Accuracy: 0.10144927536231885\n",
      "Epoch [40/300], Loss: 4.7650\n",
      "TabTransformer F1 score macro: 0.0250\n",
      "TabTransformer Test Accuracy: 0.09178743961352658\n",
      "Epoch [41/300], Loss: 2.8738\n",
      "TabTransformer F1 score macro: 0.0090\n",
      "TabTransformer Test Accuracy: 0.03864734299516908\n",
      "Epoch [42/300], Loss: 4.1589\n",
      "TabTransformer F1 score macro: 0.0205\n",
      "TabTransformer Test Accuracy: 0.07246376811594203\n",
      "Epoch [43/300], Loss: 6.0244\n",
      "TabTransformer F1 score macro: 0.0081\n",
      "TabTransformer Test Accuracy: 0.06280193236714976\n",
      "Epoch [44/300], Loss: 5.6595\n",
      "TabTransformer F1 score macro: 0.0298\n",
      "TabTransformer Test Accuracy: 0.08695652173913043\n",
      "Epoch [45/300], Loss: 3.8084\n",
      "TabTransformer F1 score macro: 0.0189\n",
      "TabTransformer Test Accuracy: 0.06763285024154589\n",
      "Epoch [46/300], Loss: 4.6230\n",
      "TabTransformer F1 score macro: 0.0098\n",
      "TabTransformer Test Accuracy: 0.04830917874396135\n",
      "Epoch [47/300], Loss: 4.4801\n",
      "TabTransformer F1 score macro: 0.0251\n",
      "TabTransformer Test Accuracy: 0.1111111111111111\n",
      "Epoch [48/300], Loss: 3.1303\n",
      "TabTransformer F1 score macro: 0.0359\n",
      "TabTransformer Test Accuracy: 0.14009661835748793\n",
      "Epoch [49/300], Loss: 6.0824\n",
      "TabTransformer F1 score macro: 0.0465\n",
      "TabTransformer Test Accuracy: 0.17391304347826086\n",
      "Epoch [50/300], Loss: 4.1547\n",
      "TabTransformer F1 score macro: 0.0563\n",
      "TabTransformer Test Accuracy: 0.18357487922705315\n",
      "Epoch [51/300], Loss: 4.1190\n",
      "TabTransformer F1 score macro: 0.0205\n",
      "TabTransformer Test Accuracy: 0.10144927536231885\n",
      "Epoch [52/300], Loss: 5.6454\n",
      "TabTransformer F1 score macro: 0.0052\n",
      "TabTransformer Test Accuracy: 0.033816425120772944\n",
      "Epoch [53/300], Loss: 3.1863\n",
      "TabTransformer F1 score macro: 0.0187\n",
      "TabTransformer Test Accuracy: 0.04830917874396135\n",
      "Epoch [54/300], Loss: 4.6652\n",
      "TabTransformer F1 score macro: 0.0282\n",
      "TabTransformer Test Accuracy: 0.09178743961352658\n",
      "Epoch [55/300], Loss: 4.9625\n",
      "TabTransformer F1 score macro: 0.0505\n",
      "TabTransformer Test Accuracy: 0.1642512077294686\n",
      "Epoch [56/300], Loss: 4.2698\n",
      "TabTransformer F1 score macro: 0.0479\n",
      "TabTransformer Test Accuracy: 0.15942028985507245\n",
      "Epoch [57/300], Loss: 4.3369\n",
      "TabTransformer F1 score macro: 0.0524\n",
      "TabTransformer Test Accuracy: 0.18840579710144928\n",
      "Epoch [58/300], Loss: 1.7395\n",
      "TabTransformer F1 score macro: 0.0745\n",
      "TabTransformer Test Accuracy: 0.21739130434782608\n",
      "Epoch [59/300], Loss: 5.3564\n",
      "TabTransformer F1 score macro: 0.0330\n",
      "TabTransformer Test Accuracy: 0.11594202898550725\n",
      "Epoch [60/300], Loss: 4.9489\n",
      "TabTransformer F1 score macro: 0.0417\n",
      "TabTransformer Test Accuracy: 0.2028985507246377\n",
      "Epoch [61/300], Loss: 3.4437\n",
      "TabTransformer F1 score macro: 0.0424\n",
      "TabTransformer Test Accuracy: 0.12077294685990338\n",
      "Epoch [62/300], Loss: 3.4326\n",
      "TabTransformer F1 score macro: 0.0308\n",
      "TabTransformer Test Accuracy: 0.12077294685990338\n",
      "Epoch [63/300], Loss: 4.6865\n",
      "TabTransformer F1 score macro: 0.0467\n",
      "TabTransformer Test Accuracy: 0.1932367149758454\n",
      "Epoch [64/300], Loss: 4.3234\n",
      "TabTransformer F1 score macro: 0.0562\n",
      "TabTransformer Test Accuracy: 0.1932367149758454\n",
      "Epoch [65/300], Loss: 4.6516\n",
      "TabTransformer F1 score macro: 0.0500\n",
      "TabTransformer Test Accuracy: 0.18840579710144928\n",
      "Epoch [66/300], Loss: 3.4930\n",
      "TabTransformer F1 score macro: 0.0763\n",
      "TabTransformer Test Accuracy: 0.22705314009661837\n",
      "Epoch [67/300], Loss: 4.6902\n",
      "TabTransformer F1 score macro: 0.0739\n",
      "TabTransformer Test Accuracy: 0.21739130434782608\n",
      "Epoch [68/300], Loss: 6.4491\n",
      "TabTransformer F1 score macro: 0.0558\n",
      "TabTransformer Test Accuracy: 0.18357487922705315\n",
      "Epoch [69/300], Loss: 3.3254\n",
      "TabTransformer F1 score macro: 0.0492\n",
      "TabTransformer Test Accuracy: 0.178743961352657\n",
      "Epoch [70/300], Loss: 4.4030\n",
      "TabTransformer F1 score macro: 0.0625\n",
      "TabTransformer Test Accuracy: 0.22705314009661837\n",
      "Epoch [71/300], Loss: 5.6340\n",
      "TabTransformer F1 score macro: 0.0468\n",
      "TabTransformer Test Accuracy: 0.1497584541062802\n",
      "Epoch [72/300], Loss: 4.1670\n",
      "TabTransformer F1 score macro: 0.0738\n",
      "TabTransformer Test Accuracy: 0.2753623188405797\n",
      "Epoch [73/300], Loss: 4.2354\n",
      "TabTransformer F1 score macro: 0.1268\n",
      "TabTransformer Test Accuracy: 0.32367149758454106\n",
      "Epoch [74/300], Loss: 4.0006\n",
      "TabTransformer F1 score macro: 0.0712\n",
      "TabTransformer Test Accuracy: 0.19806763285024154\n",
      "Epoch [75/300], Loss: 4.4766\n",
      "TabTransformer F1 score macro: 0.0633\n",
      "TabTransformer Test Accuracy: 0.2560386473429952\n",
      "Epoch [76/300], Loss: 4.4099\n",
      "TabTransformer F1 score macro: 0.0741\n",
      "TabTransformer Test Accuracy: 0.27053140096618356\n",
      "Epoch [77/300], Loss: 1.5721\n",
      "TabTransformer F1 score macro: 0.0567\n",
      "TabTransformer Test Accuracy: 0.18357487922705315\n",
      "Epoch [78/300], Loss: 3.6546\n",
      "TabTransformer F1 score macro: 0.0766\n",
      "TabTransformer Test Accuracy: 0.23671497584541062\n",
      "Epoch [79/300], Loss: 4.5028\n",
      "TabTransformer F1 score macro: 0.0444\n",
      "TabTransformer Test Accuracy: 0.18840579710144928\n",
      "Epoch [80/300], Loss: 2.7253\n",
      "TabTransformer F1 score macro: 0.0587\n",
      "TabTransformer Test Accuracy: 0.15458937198067632\n",
      "Epoch [81/300], Loss: 5.0098\n",
      "TabTransformer F1 score macro: 0.0694\n",
      "TabTransformer Test Accuracy: 0.19806763285024154\n",
      "Epoch [82/300], Loss: 6.0204\n",
      "TabTransformer F1 score macro: 0.0449\n",
      "TabTransformer Test Accuracy: 0.17391304347826086\n",
      "Epoch [83/300], Loss: 2.6611\n",
      "TabTransformer F1 score macro: 0.0925\n",
      "TabTransformer Test Accuracy: 0.27053140096618356\n",
      "Epoch [84/300], Loss: 2.5288\n",
      "TabTransformer F1 score macro: 0.1217\n",
      "TabTransformer Test Accuracy: 0.36231884057971014\n",
      "Epoch [85/300], Loss: 3.2342\n",
      "TabTransformer F1 score macro: 0.1035\n",
      "TabTransformer Test Accuracy: 0.3188405797101449\n",
      "Epoch [86/300], Loss: 1.5210\n",
      "TabTransformer F1 score macro: 0.1180\n",
      "TabTransformer Test Accuracy: 0.357487922705314\n",
      "Epoch [87/300], Loss: 2.3815\n",
      "TabTransformer F1 score macro: 0.0928\n",
      "TabTransformer Test Accuracy: 0.2898550724637681\n",
      "Epoch [88/300], Loss: 4.0899\n",
      "TabTransformer F1 score macro: 0.0957\n",
      "TabTransformer Test Accuracy: 0.32367149758454106\n",
      "Epoch [89/300], Loss: 1.5621\n",
      "TabTransformer F1 score macro: 0.1104\n",
      "TabTransformer Test Accuracy: 0.357487922705314\n",
      "Epoch [90/300], Loss: 3.0873\n",
      "TabTransformer F1 score macro: 0.1151\n",
      "TabTransformer Test Accuracy: 0.3140096618357488\n",
      "Epoch [91/300], Loss: 3.7505\n",
      "TabTransformer F1 score macro: 0.0953\n",
      "TabTransformer Test Accuracy: 0.2560386473429952\n",
      "Epoch [92/300], Loss: 3.5714\n",
      "TabTransformer F1 score macro: 0.0999\n",
      "TabTransformer Test Accuracy: 0.27053140096618356\n",
      "Epoch [93/300], Loss: 3.1864\n",
      "TabTransformer F1 score macro: 0.0898\n",
      "TabTransformer Test Accuracy: 0.2560386473429952\n",
      "Epoch [94/300], Loss: 4.3069\n",
      "TabTransformer F1 score macro: 0.1090\n",
      "TabTransformer Test Accuracy: 0.3285024154589372\n",
      "Epoch [95/300], Loss: 5.5259\n",
      "TabTransformer F1 score macro: 0.1202\n",
      "TabTransformer Test Accuracy: 0.32367149758454106\n",
      "Epoch [96/300], Loss: 0.9939\n",
      "TabTransformer F1 score macro: 0.1303\n",
      "TabTransformer Test Accuracy: 0.3526570048309179\n",
      "Epoch [97/300], Loss: 4.7312\n",
      "TabTransformer F1 score macro: 0.1210\n",
      "TabTransformer Test Accuracy: 0.33816425120772947\n",
      "Epoch [98/300], Loss: 0.8080\n",
      "TabTransformer F1 score macro: 0.1344\n",
      "TabTransformer Test Accuracy: 0.3671497584541063\n",
      "Epoch [99/300], Loss: 3.2593\n",
      "TabTransformer F1 score macro: 0.1495\n",
      "TabTransformer Test Accuracy: 0.3961352657004831\n",
      "Epoch [100/300], Loss: 2.4715\n",
      "TabTransformer F1 score macro: 0.1245\n",
      "TabTransformer Test Accuracy: 0.3961352657004831\n",
      "Epoch [101/300], Loss: 0.0684\n",
      "TabTransformer F1 score macro: 0.1218\n",
      "TabTransformer Test Accuracy: 0.36231884057971014\n",
      "Epoch [102/300], Loss: 1.7739\n",
      "TabTransformer F1 score macro: 0.1528\n",
      "TabTransformer Test Accuracy: 0.37681159420289856\n",
      "Epoch [103/300], Loss: 5.3189\n",
      "TabTransformer F1 score macro: 0.1133\n",
      "TabTransformer Test Accuracy: 0.3188405797101449\n",
      "Epoch [104/300], Loss: 1.7863\n",
      "TabTransformer F1 score macro: 0.1358\n",
      "TabTransformer Test Accuracy: 0.36231884057971014\n",
      "Epoch [105/300], Loss: 0.0900\n",
      "TabTransformer F1 score macro: 0.1353\n",
      "TabTransformer Test Accuracy: 0.37681159420289856\n",
      "Epoch [106/300], Loss: 4.6268\n",
      "TabTransformer F1 score macro: 0.1244\n",
      "TabTransformer Test Accuracy: 0.3719806763285024\n",
      "Epoch [107/300], Loss: 3.0046\n",
      "TabTransformer F1 score macro: 0.1389\n",
      "TabTransformer Test Accuracy: 0.41545893719806765\n",
      "Epoch [108/300], Loss: 3.0264\n",
      "TabTransformer F1 score macro: 0.1768\n",
      "TabTransformer Test Accuracy: 0.4492753623188406\n",
      "Epoch [109/300], Loss: 3.3650\n",
      "TabTransformer F1 score macro: 0.1643\n",
      "TabTransformer Test Accuracy: 0.4057971014492754\n",
      "Epoch [110/300], Loss: 4.6346\n",
      "TabTransformer F1 score macro: 0.1381\n",
      "TabTransformer Test Accuracy: 0.38164251207729466\n",
      "Epoch [111/300], Loss: 2.9622\n",
      "TabTransformer F1 score macro: 0.1214\n",
      "TabTransformer Test Accuracy: 0.3719806763285024\n",
      "Epoch [112/300], Loss: 2.0062\n",
      "TabTransformer F1 score macro: 0.1309\n",
      "TabTransformer Test Accuracy: 0.38164251207729466\n",
      "Epoch [113/300], Loss: 0.1478\n",
      "TabTransformer F1 score macro: 0.1496\n",
      "TabTransformer Test Accuracy: 0.3961352657004831\n",
      "Epoch [114/300], Loss: 2.6630\n",
      "TabTransformer F1 score macro: 0.1426\n",
      "TabTransformer Test Accuracy: 0.3719806763285024\n",
      "Epoch [115/300], Loss: 2.8171\n",
      "TabTransformer F1 score macro: 0.1166\n",
      "TabTransformer Test Accuracy: 0.34299516908212563\n",
      "Epoch [116/300], Loss: 2.7051\n",
      "TabTransformer F1 score macro: 0.1066\n",
      "TabTransformer Test Accuracy: 0.2995169082125604\n",
      "Epoch [117/300], Loss: 2.6135\n",
      "TabTransformer F1 score macro: 0.1350\n",
      "TabTransformer Test Accuracy: 0.357487922705314\n",
      "Epoch [118/300], Loss: 1.4209\n",
      "TabTransformer F1 score macro: 0.1408\n",
      "TabTransformer Test Accuracy: 0.38164251207729466\n",
      "Epoch [119/300], Loss: 3.2071\n",
      "TabTransformer F1 score macro: 0.1590\n",
      "TabTransformer Test Accuracy: 0.3864734299516908\n",
      "Epoch [120/300], Loss: 1.1725\n",
      "TabTransformer F1 score macro: 0.1496\n",
      "TabTransformer Test Accuracy: 0.3864734299516908\n",
      "Epoch [121/300], Loss: 2.8233\n",
      "TabTransformer F1 score macro: 0.1977\n",
      "TabTransformer Test Accuracy: 0.4492753623188406\n",
      "Epoch [122/300], Loss: 1.2078\n",
      "TabTransformer F1 score macro: 0.1900\n",
      "TabTransformer Test Accuracy: 0.46859903381642515\n",
      "Epoch [123/300], Loss: 2.5239\n",
      "TabTransformer F1 score macro: 0.1766\n",
      "TabTransformer Test Accuracy: 0.42995169082125606\n",
      "Epoch [124/300], Loss: 2.0405\n",
      "TabTransformer F1 score macro: 0.1540\n",
      "TabTransformer Test Accuracy: 0.40096618357487923\n",
      "Epoch [125/300], Loss: 1.4425\n",
      "TabTransformer F1 score macro: 0.1852\n",
      "TabTransformer Test Accuracy: 0.42995169082125606\n",
      "Epoch [126/300], Loss: 2.4305\n",
      "TabTransformer F1 score macro: 0.1802\n",
      "TabTransformer Test Accuracy: 0.46859903381642515\n",
      "Epoch [127/300], Loss: 1.5655\n",
      "TabTransformer F1 score macro: 0.1612\n",
      "TabTransformer Test Accuracy: 0.3961352657004831\n",
      "Epoch [128/300], Loss: 2.4445\n",
      "TabTransformer F1 score macro: 0.1687\n",
      "TabTransformer Test Accuracy: 0.41545893719806765\n",
      "Epoch [129/300], Loss: 4.0987\n",
      "TabTransformer F1 score macro: 0.1771\n",
      "TabTransformer Test Accuracy: 0.41545893719806765\n",
      "Epoch [130/300], Loss: 4.9664\n",
      "TabTransformer F1 score macro: 0.1796\n",
      "TabTransformer Test Accuracy: 0.42995169082125606\n",
      "Epoch [131/300], Loss: 3.7503\n",
      "TabTransformer F1 score macro: 0.1677\n",
      "TabTransformer Test Accuracy: 0.4396135265700483\n",
      "Epoch [132/300], Loss: 3.5074\n",
      "TabTransformer F1 score macro: 0.1999\n",
      "TabTransformer Test Accuracy: 0.4830917874396135\n",
      "Epoch [133/300], Loss: 0.3872\n",
      "TabTransformer F1 score macro: 0.2084\n",
      "TabTransformer Test Accuracy: 0.46859903381642515\n",
      "Epoch [134/300], Loss: 0.0618\n",
      "TabTransformer F1 score macro: 0.1927\n",
      "TabTransformer Test Accuracy: 0.45410628019323673\n",
      "Epoch [135/300], Loss: 0.2173\n",
      "TabTransformer F1 score macro: 0.2421\n",
      "TabTransformer Test Accuracy: 0.5169082125603864\n",
      "Epoch [136/300], Loss: 1.0255\n",
      "TabTransformer F1 score macro: 0.2577\n",
      "TabTransformer Test Accuracy: 0.4975845410628019\n",
      "Epoch [137/300], Loss: 2.2799\n",
      "TabTransformer F1 score macro: 0.2429\n",
      "TabTransformer Test Accuracy: 0.5072463768115942\n",
      "Epoch [138/300], Loss: 0.0737\n",
      "TabTransformer F1 score macro: 0.2134\n",
      "TabTransformer Test Accuracy: 0.4975845410628019\n",
      "Epoch [139/300], Loss: 0.5683\n",
      "TabTransformer F1 score macro: 0.2382\n",
      "TabTransformer Test Accuracy: 0.5120772946859904\n",
      "Epoch [140/300], Loss: 3.8563\n",
      "TabTransformer F1 score macro: 0.2360\n",
      "TabTransformer Test Accuracy: 0.5024154589371981\n",
      "Epoch [141/300], Loss: 3.2553\n",
      "TabTransformer F1 score macro: 0.2297\n",
      "TabTransformer Test Accuracy: 0.48792270531400966\n",
      "Epoch [142/300], Loss: 4.3618\n",
      "TabTransformer F1 score macro: 0.2115\n",
      "TabTransformer Test Accuracy: 0.5072463768115942\n",
      "Epoch [143/300], Loss: 3.9696\n",
      "TabTransformer F1 score macro: 0.2281\n",
      "TabTransformer Test Accuracy: 0.4830917874396135\n",
      "Epoch [144/300], Loss: 1.8627\n",
      "TabTransformer F1 score macro: 0.2436\n",
      "TabTransformer Test Accuracy: 0.5120772946859904\n",
      "Epoch [145/300], Loss: 2.0917\n",
      "TabTransformer F1 score macro: 0.2617\n",
      "TabTransformer Test Accuracy: 0.5410628019323671\n",
      "Epoch [146/300], Loss: 4.2907\n",
      "TabTransformer F1 score macro: 0.2280\n",
      "TabTransformer Test Accuracy: 0.4975845410628019\n",
      "Epoch [147/300], Loss: 1.3153\n",
      "TabTransformer F1 score macro: 0.2262\n",
      "TabTransformer Test Accuracy: 0.5120772946859904\n",
      "Epoch [148/300], Loss: 0.1164\n",
      "TabTransformer F1 score macro: 0.2435\n",
      "TabTransformer Test Accuracy: 0.5265700483091788\n",
      "Epoch [149/300], Loss: 3.3919\n",
      "TabTransformer F1 score macro: 0.2413\n",
      "TabTransformer Test Accuracy: 0.5169082125603864\n",
      "Epoch [150/300], Loss: 3.7006\n",
      "TabTransformer F1 score macro: 0.2264\n",
      "TabTransformer Test Accuracy: 0.4927536231884058\n",
      "Epoch [151/300], Loss: 2.0322\n",
      "TabTransformer F1 score macro: 0.2282\n",
      "TabTransformer Test Accuracy: 0.4782608695652174\n",
      "Epoch [152/300], Loss: 1.7682\n",
      "TabTransformer F1 score macro: 0.1969\n",
      "TabTransformer Test Accuracy: 0.46859903381642515\n",
      "Epoch [153/300], Loss: 5.5052\n",
      "TabTransformer F1 score macro: 0.2055\n",
      "TabTransformer Test Accuracy: 0.45410628019323673\n",
      "Epoch [154/300], Loss: 0.4655\n",
      "TabTransformer F1 score macro: 0.1756\n",
      "TabTransformer Test Accuracy: 0.42028985507246375\n",
      "Epoch [155/300], Loss: 2.5009\n",
      "TabTransformer F1 score macro: 0.1947\n",
      "TabTransformer Test Accuracy: 0.47342995169082125\n",
      "Epoch [156/300], Loss: 1.4237\n",
      "TabTransformer F1 score macro: 0.2402\n",
      "TabTransformer Test Accuracy: 0.5072463768115942\n",
      "Epoch [157/300], Loss: 1.5997\n",
      "TabTransformer F1 score macro: 0.2546\n",
      "TabTransformer Test Accuracy: 0.5652173913043478\n",
      "Epoch [158/300], Loss: 2.2603\n",
      "TabTransformer F1 score macro: 0.2536\n",
      "TabTransformer Test Accuracy: 0.5024154589371981\n",
      "Epoch [159/300], Loss: 2.8135\n",
      "TabTransformer F1 score macro: 0.2403\n",
      "TabTransformer Test Accuracy: 0.5217391304347826\n",
      "Epoch [160/300], Loss: 2.1257\n",
      "TabTransformer F1 score macro: 0.2293\n",
      "TabTransformer Test Accuracy: 0.5072463768115942\n",
      "Epoch [161/300], Loss: 0.6906\n",
      "TabTransformer F1 score macro: 0.2366\n",
      "TabTransformer Test Accuracy: 0.5169082125603864\n",
      "Epoch [162/300], Loss: 1.0996\n",
      "TabTransformer F1 score macro: 0.2751\n",
      "TabTransformer Test Accuracy: 0.5458937198067633\n",
      "Epoch [163/300], Loss: 0.5242\n",
      "TabTransformer F1 score macro: 0.2519\n",
      "TabTransformer Test Accuracy: 0.5410628019323671\n",
      "Epoch [164/300], Loss: 0.0624\n",
      "TabTransformer F1 score macro: 0.2401\n",
      "TabTransformer Test Accuracy: 0.5120772946859904\n",
      "Epoch [165/300], Loss: 1.0999\n",
      "TabTransformer F1 score macro: 0.2406\n",
      "TabTransformer Test Accuracy: 0.5217391304347826\n",
      "Epoch [166/300], Loss: 0.9652\n",
      "TabTransformer F1 score macro: 0.2686\n",
      "TabTransformer Test Accuracy: 0.5217391304347826\n",
      "Epoch [167/300], Loss: 1.5418\n",
      "TabTransformer F1 score macro: 0.2438\n",
      "TabTransformer Test Accuracy: 0.5169082125603864\n",
      "Epoch [168/300], Loss: 0.7652\n",
      "TabTransformer F1 score macro: 0.2759\n",
      "TabTransformer Test Accuracy: 0.5652173913043478\n",
      "Epoch [169/300], Loss: 2.6803\n",
      "TabTransformer F1 score macro: 0.2830\n",
      "TabTransformer Test Accuracy: 0.5362318840579711\n",
      "Epoch [170/300], Loss: 2.1347\n",
      "TabTransformer F1 score macro: 0.2777\n",
      "TabTransformer Test Accuracy: 0.5700483091787439\n",
      "Epoch [171/300], Loss: 0.0258\n",
      "TabTransformer F1 score macro: 0.3267\n",
      "TabTransformer Test Accuracy: 0.5845410628019324\n",
      "Epoch [172/300], Loss: 1.6993\n",
      "TabTransformer F1 score macro: 0.2905\n",
      "TabTransformer Test Accuracy: 0.5700483091787439\n",
      "Epoch [173/300], Loss: 0.8414\n",
      "TabTransformer F1 score macro: 0.3151\n",
      "TabTransformer Test Accuracy: 0.5893719806763285\n",
      "Epoch [174/300], Loss: 0.9790\n",
      "TabTransformer F1 score macro: 0.2851\n",
      "TabTransformer Test Accuracy: 0.5652173913043478\n",
      "Epoch [175/300], Loss: 1.1352\n",
      "TabTransformer F1 score macro: 0.2506\n",
      "TabTransformer Test Accuracy: 0.5507246376811594\n",
      "Epoch [176/300], Loss: 0.4937\n",
      "TabTransformer F1 score macro: 0.2738\n",
      "TabTransformer Test Accuracy: 0.5507246376811594\n",
      "Epoch [177/300], Loss: 2.4034\n",
      "TabTransformer F1 score macro: 0.2671\n",
      "TabTransformer Test Accuracy: 0.5555555555555556\n",
      "Epoch [178/300], Loss: 0.1876\n",
      "TabTransformer F1 score macro: 0.2982\n",
      "TabTransformer Test Accuracy: 0.5555555555555556\n",
      "Epoch [179/300], Loss: 0.5701\n",
      "TabTransformer F1 score macro: 0.2779\n",
      "TabTransformer Test Accuracy: 0.5314009661835749\n",
      "Epoch [180/300], Loss: 3.0661\n",
      "TabTransformer F1 score macro: 0.2907\n",
      "TabTransformer Test Accuracy: 0.5748792270531401\n",
      "Epoch [181/300], Loss: 2.1226\n",
      "TabTransformer F1 score macro: 0.2752\n",
      "TabTransformer Test Accuracy: 0.5265700483091788\n",
      "Epoch [182/300], Loss: 1.7057\n",
      "TabTransformer F1 score macro: 0.2705\n",
      "TabTransformer Test Accuracy: 0.5507246376811594\n",
      "Epoch [183/300], Loss: 2.0121\n",
      "TabTransformer F1 score macro: 0.2439\n",
      "TabTransformer Test Accuracy: 0.5024154589371981\n",
      "Epoch [184/300], Loss: 2.2473\n",
      "TabTransformer F1 score macro: 0.2597\n",
      "TabTransformer Test Accuracy: 0.5314009661835749\n",
      "Epoch [185/300], Loss: 0.8658\n",
      "TabTransformer F1 score macro: 0.2500\n",
      "TabTransformer Test Accuracy: 0.5120772946859904\n",
      "Epoch [186/300], Loss: 2.0697\n",
      "TabTransformer F1 score macro: 0.2927\n",
      "TabTransformer Test Accuracy: 0.5603864734299517\n",
      "Epoch [187/300], Loss: 1.7342\n",
      "TabTransformer F1 score macro: 0.2756\n",
      "TabTransformer Test Accuracy: 0.5458937198067633\n",
      "Epoch [188/300], Loss: 0.0142\n",
      "TabTransformer F1 score macro: 0.2618\n",
      "TabTransformer Test Accuracy: 0.5555555555555556\n",
      "Epoch [189/300], Loss: 0.1054\n",
      "TabTransformer F1 score macro: 0.3031\n",
      "TabTransformer Test Accuracy: 0.5942028985507246\n",
      "Epoch [190/300], Loss: 0.9274\n",
      "TabTransformer F1 score macro: 0.2912\n",
      "TabTransformer Test Accuracy: 0.5748792270531401\n",
      "Epoch [191/300], Loss: 1.5320\n",
      "TabTransformer F1 score macro: 0.3258\n",
      "TabTransformer Test Accuracy: 0.6086956521739131\n",
      "Epoch [192/300], Loss: 0.9726\n",
      "TabTransformer F1 score macro: 0.3530\n",
      "TabTransformer Test Accuracy: 0.6280193236714976\n",
      "Epoch [193/300], Loss: 0.3192\n",
      "TabTransformer F1 score macro: 0.3183\n",
      "TabTransformer Test Accuracy: 0.6086956521739131\n",
      "Epoch [194/300], Loss: 0.4036\n",
      "TabTransformer F1 score macro: 0.3265\n",
      "TabTransformer Test Accuracy: 0.6038647342995169\n",
      "Epoch [195/300], Loss: 0.5250\n",
      "TabTransformer F1 score macro: 0.3169\n",
      "TabTransformer Test Accuracy: 0.6038647342995169\n",
      "Epoch [196/300], Loss: 1.8229\n",
      "TabTransformer F1 score macro: 0.3332\n",
      "TabTransformer Test Accuracy: 0.6135265700483091\n",
      "Epoch [197/300], Loss: 0.2612\n",
      "TabTransformer F1 score macro: 0.2958\n",
      "TabTransformer Test Accuracy: 0.5990338164251208\n",
      "Epoch [198/300], Loss: 1.0181\n",
      "TabTransformer F1 score macro: 0.3173\n",
      "TabTransformer Test Accuracy: 0.5990338164251208\n",
      "Epoch [199/300], Loss: 0.1981\n",
      "TabTransformer F1 score macro: 0.3238\n",
      "TabTransformer Test Accuracy: 0.6086956521739131\n",
      "Epoch [200/300], Loss: 0.0609\n",
      "TabTransformer F1 score macro: 0.3280\n",
      "TabTransformer Test Accuracy: 0.6086956521739131\n",
      "Epoch [201/300], Loss: 0.6974\n",
      "TabTransformer F1 score macro: 0.2902\n",
      "TabTransformer Test Accuracy: 0.5893719806763285\n",
      "Epoch [202/300], Loss: 0.3235\n",
      "TabTransformer F1 score macro: 0.2958\n",
      "TabTransformer Test Accuracy: 0.5893719806763285\n",
      "Epoch [203/300], Loss: 0.6066\n",
      "TabTransformer F1 score macro: 0.2751\n",
      "TabTransformer Test Accuracy: 0.5603864734299517\n",
      "Epoch [204/300], Loss: 0.0902\n",
      "TabTransformer F1 score macro: 0.2997\n",
      "TabTransformer Test Accuracy: 0.5652173913043478\n",
      "Epoch [205/300], Loss: 0.2043\n",
      "TabTransformer F1 score macro: 0.2850\n",
      "TabTransformer Test Accuracy: 0.5362318840579711\n",
      "Epoch [206/300], Loss: 2.3158\n",
      "TabTransformer F1 score macro: 0.2801\n",
      "TabTransformer Test Accuracy: 0.5314009661835749\n",
      "Epoch [207/300], Loss: 1.2488\n",
      "TabTransformer F1 score macro: 0.2651\n",
      "TabTransformer Test Accuracy: 0.4975845410628019\n",
      "Epoch [208/300], Loss: 1.6515\n",
      "TabTransformer F1 score macro: 0.2534\n",
      "TabTransformer Test Accuracy: 0.5217391304347826\n",
      "Epoch [209/300], Loss: 0.1591\n",
      "TabTransformer F1 score macro: 0.2745\n",
      "TabTransformer Test Accuracy: 0.5603864734299517\n",
      "Epoch [210/300], Loss: 0.5564\n",
      "TabTransformer F1 score macro: 0.3022\n",
      "TabTransformer Test Accuracy: 0.5652173913043478\n",
      "Epoch [211/300], Loss: 0.3741\n",
      "TabTransformer F1 score macro: 0.3212\n",
      "TabTransformer Test Accuracy: 0.5845410628019324\n",
      "Epoch [212/300], Loss: 0.1338\n",
      "TabTransformer F1 score macro: 0.3478\n",
      "TabTransformer Test Accuracy: 0.6135265700483091\n",
      "Epoch [213/300], Loss: 0.2961\n",
      "TabTransformer F1 score macro: 0.3287\n",
      "TabTransformer Test Accuracy: 0.6086956521739131\n",
      "Epoch [214/300], Loss: 1.5786\n",
      "TabTransformer F1 score macro: 0.3340\n",
      "TabTransformer Test Accuracy: 0.6135265700483091\n",
      "Epoch [215/300], Loss: 2.2220\n",
      "TabTransformer F1 score macro: 0.3176\n",
      "TabTransformer Test Accuracy: 0.6183574879227053\n",
      "Epoch [216/300], Loss: 0.1003\n",
      "TabTransformer F1 score macro: 0.3421\n",
      "TabTransformer Test Accuracy: 0.6231884057971014\n",
      "Epoch [217/300], Loss: 0.0224\n",
      "TabTransformer F1 score macro: 0.3265\n",
      "TabTransformer Test Accuracy: 0.6135265700483091\n",
      "Epoch [218/300], Loss: 0.5989\n",
      "TabTransformer F1 score macro: 0.3620\n",
      "TabTransformer Test Accuracy: 0.6376811594202898\n",
      "Epoch [219/300], Loss: 0.0901\n",
      "TabTransformer F1 score macro: 0.3476\n",
      "TabTransformer Test Accuracy: 0.6183574879227053\n",
      "Epoch [220/300], Loss: 0.6274\n",
      "TabTransformer F1 score macro: 0.3194\n",
      "TabTransformer Test Accuracy: 0.6086956521739131\n",
      "Epoch [221/300], Loss: 0.0523\n",
      "TabTransformer F1 score macro: 0.3473\n",
      "TabTransformer Test Accuracy: 0.6183574879227053\n",
      "Epoch [222/300], Loss: 0.9235\n",
      "TabTransformer F1 score macro: 0.3062\n",
      "TabTransformer Test Accuracy: 0.6086956521739131\n",
      "Epoch [223/300], Loss: 0.0198\n",
      "TabTransformer F1 score macro: 0.3290\n",
      "TabTransformer Test Accuracy: 0.6183574879227053\n",
      "Epoch [224/300], Loss: 0.1276\n",
      "TabTransformer F1 score macro: 0.3373\n",
      "TabTransformer Test Accuracy: 0.6183574879227053\n",
      "Epoch [225/300], Loss: 0.0823\n",
      "TabTransformer F1 score macro: 0.3194\n",
      "TabTransformer Test Accuracy: 0.6135265700483091\n",
      "Epoch [226/300], Loss: 0.0719\n",
      "TabTransformer F1 score macro: 0.3392\n",
      "TabTransformer Test Accuracy: 0.6280193236714976\n",
      "Epoch [227/300], Loss: 0.3765\n",
      "TabTransformer F1 score macro: 0.3072\n",
      "TabTransformer Test Accuracy: 0.5893719806763285\n",
      "Epoch [228/300], Loss: 0.7298\n",
      "TabTransformer F1 score macro: 0.3312\n",
      "TabTransformer Test Accuracy: 0.6086956521739131\n",
      "Epoch [229/300], Loss: 0.7902\n",
      "TabTransformer F1 score macro: 0.2928\n",
      "TabTransformer Test Accuracy: 0.5893719806763285\n",
      "Epoch [230/300], Loss: 0.9266\n",
      "TabTransformer F1 score macro: 0.2256\n",
      "TabTransformer Test Accuracy: 0.5024154589371981\n",
      "Epoch [231/300], Loss: 0.8790\n",
      "TabTransformer F1 score macro: 0.1975\n",
      "TabTransformer Test Accuracy: 0.43478260869565216\n",
      "Epoch [232/300], Loss: 0.2485\n",
      "TabTransformer F1 score macro: 0.2499\n",
      "TabTransformer Test Accuracy: 0.5072463768115942\n",
      "Epoch [233/300], Loss: 2.8633\n",
      "TabTransformer F1 score macro: 0.1959\n",
      "TabTransformer Test Accuracy: 0.43478260869565216\n",
      "Epoch [234/300], Loss: 3.0140\n",
      "TabTransformer F1 score macro: 0.2042\n",
      "TabTransformer Test Accuracy: 0.4444444444444444\n",
      "Epoch [235/300], Loss: 0.2390\n",
      "TabTransformer F1 score macro: 0.2669\n",
      "TabTransformer Test Accuracy: 0.5410628019323671\n",
      "Epoch [236/300], Loss: 0.1500\n",
      "TabTransformer F1 score macro: 0.2632\n",
      "TabTransformer Test Accuracy: 0.5362318840579711\n",
      "Epoch [237/300], Loss: 0.0209\n",
      "TabTransformer F1 score macro: 0.3091\n",
      "TabTransformer Test Accuracy: 0.5990338164251208\n",
      "Epoch [238/300], Loss: 0.5065\n",
      "TabTransformer F1 score macro: 0.3712\n",
      "TabTransformer Test Accuracy: 0.6328502415458938\n",
      "Epoch [239/300], Loss: 0.4473\n",
      "TabTransformer F1 score macro: 0.3792\n",
      "TabTransformer Test Accuracy: 0.642512077294686\n",
      "Epoch [240/300], Loss: 0.0999\n",
      "TabTransformer F1 score macro: 0.3482\n",
      "TabTransformer Test Accuracy: 0.6183574879227053\n",
      "Epoch [241/300], Loss: 0.1863\n",
      "TabTransformer F1 score macro: 0.3621\n",
      "TabTransformer Test Accuracy: 0.6328502415458938\n",
      "Epoch [242/300], Loss: 0.2771\n",
      "TabTransformer F1 score macro: 0.3683\n",
      "TabTransformer Test Accuracy: 0.642512077294686\n",
      "Epoch [243/300], Loss: 0.6136\n",
      "TabTransformer F1 score macro: 0.3828\n",
      "TabTransformer Test Accuracy: 0.642512077294686\n",
      "Epoch [244/300], Loss: 0.1673\n",
      "TabTransformer F1 score macro: 0.3265\n",
      "TabTransformer Test Accuracy: 0.6231884057971014\n",
      "Epoch [245/300], Loss: 0.2926\n",
      "TabTransformer F1 score macro: 0.3627\n",
      "TabTransformer Test Accuracy: 0.6328502415458938\n",
      "Epoch [246/300], Loss: 0.0260\n",
      "TabTransformer F1 score macro: 0.3705\n",
      "TabTransformer Test Accuracy: 0.642512077294686\n",
      "Epoch [247/300], Loss: 0.6230\n",
      "TabTransformer F1 score macro: 0.3506\n",
      "TabTransformer Test Accuracy: 0.6280193236714976\n",
      "Epoch [248/300], Loss: 0.0728\n",
      "TabTransformer F1 score macro: 0.3765\n",
      "TabTransformer Test Accuracy: 0.6376811594202898\n",
      "Epoch [249/300], Loss: 0.0232\n",
      "TabTransformer F1 score macro: 0.3846\n",
      "TabTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [250/300], Loss: 0.2601\n",
      "TabTransformer F1 score macro: 0.3651\n",
      "TabTransformer Test Accuracy: 0.642512077294686\n",
      "Epoch [251/300], Loss: 0.6034\n",
      "TabTransformer F1 score macro: 0.3666\n",
      "TabTransformer Test Accuracy: 0.642512077294686\n",
      "Epoch [252/300], Loss: 0.0837\n",
      "TabTransformer F1 score macro: 0.3568\n",
      "TabTransformer Test Accuracy: 0.642512077294686\n",
      "Epoch [253/300], Loss: 0.0023\n",
      "TabTransformer F1 score macro: 0.3657\n",
      "TabTransformer Test Accuracy: 0.642512077294686\n",
      "Epoch [254/300], Loss: 0.0484\n",
      "TabTransformer F1 score macro: 0.3722\n",
      "TabTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [255/300], Loss: 0.0909\n",
      "TabTransformer F1 score macro: 0.3638\n",
      "TabTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [256/300], Loss: 0.3746\n",
      "TabTransformer F1 score macro: 0.3821\n",
      "TabTransformer Test Accuracy: 0.6521739130434783\n",
      "Epoch [257/300], Loss: 0.0727\n",
      "TabTransformer F1 score macro: 0.3490\n",
      "TabTransformer Test Accuracy: 0.642512077294686\n",
      "Epoch [258/300], Loss: 0.1110\n",
      "TabTransformer F1 score macro: 0.3331\n",
      "TabTransformer Test Accuracy: 0.6328502415458938\n",
      "Epoch [259/300], Loss: 0.1753\n",
      "TabTransformer F1 score macro: 0.3673\n",
      "TabTransformer Test Accuracy: 0.642512077294686\n",
      "Epoch [260/300], Loss: 0.0393\n",
      "TabTransformer F1 score macro: 0.3665\n",
      "TabTransformer Test Accuracy: 0.6376811594202898\n",
      "Epoch [261/300], Loss: 0.5868\n",
      "TabTransformer F1 score macro: 0.3733\n",
      "TabTransformer Test Accuracy: 0.6570048309178744\n",
      "Epoch [262/300], Loss: 0.0960\n",
      "TabTransformer F1 score macro: 0.3772\n",
      "TabTransformer Test Accuracy: 0.6521739130434783\n",
      "Epoch [263/300], Loss: 0.0606\n",
      "TabTransformer F1 score macro: 0.3617\n",
      "TabTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [264/300], Loss: 0.0636\n",
      "TabTransformer F1 score macro: 0.3770\n",
      "TabTransformer Test Accuracy: 0.6570048309178744\n",
      "Epoch [265/300], Loss: 0.3690\n",
      "TabTransformer F1 score macro: 0.3812\n",
      "TabTransformer Test Accuracy: 0.6521739130434783\n",
      "Epoch [266/300], Loss: 0.0069\n",
      "TabTransformer F1 score macro: 0.3478\n",
      "TabTransformer Test Accuracy: 0.6376811594202898\n",
      "Epoch [267/300], Loss: 0.0412\n",
      "TabTransformer F1 score macro: 0.3668\n",
      "TabTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [268/300], Loss: 0.0497\n",
      "TabTransformer F1 score macro: 0.3772\n",
      "TabTransformer Test Accuracy: 0.6570048309178744\n",
      "Epoch [269/300], Loss: 0.0144\n",
      "TabTransformer F1 score macro: 0.3615\n",
      "TabTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [270/300], Loss: 0.4783\n",
      "TabTransformer F1 score macro: 0.3622\n",
      "TabTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [271/300], Loss: 0.0348\n",
      "TabTransformer F1 score macro: 0.3567\n",
      "TabTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [272/300], Loss: 0.0357\n",
      "TabTransformer F1 score macro: 0.3739\n",
      "TabTransformer Test Accuracy: 0.6521739130434783\n",
      "Epoch [273/300], Loss: 0.7779\n",
      "TabTransformer F1 score macro: 0.3862\n",
      "TabTransformer Test Accuracy: 0.6666666666666666\n",
      "Epoch [274/300], Loss: 0.0194\n",
      "TabTransformer F1 score macro: 0.3540\n",
      "TabTransformer Test Accuracy: 0.642512077294686\n",
      "Epoch [275/300], Loss: 0.0041\n",
      "TabTransformer F1 score macro: 0.3572\n",
      "TabTransformer Test Accuracy: 0.642512077294686\n",
      "Epoch [276/300], Loss: 0.1674\n",
      "TabTransformer F1 score macro: 0.3826\n",
      "TabTransformer Test Accuracy: 0.6618357487922706\n",
      "Epoch [277/300], Loss: 0.0872\n",
      "TabTransformer F1 score macro: 0.3580\n",
      "TabTransformer Test Accuracy: 0.6521739130434783\n",
      "Epoch [278/300], Loss: 0.1686\n",
      "TabTransformer F1 score macro: 0.3612\n",
      "TabTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [279/300], Loss: 0.0462\n",
      "TabTransformer F1 score macro: 0.3671\n",
      "TabTransformer Test Accuracy: 0.6521739130434783\n",
      "Epoch [280/300], Loss: 0.7923\n",
      "TabTransformer F1 score macro: 0.3548\n",
      "TabTransformer Test Accuracy: 0.6376811594202898\n",
      "Epoch [281/300], Loss: 0.0725\n",
      "TabTransformer F1 score macro: 0.3681\n",
      "TabTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [282/300], Loss: 0.0500\n",
      "TabTransformer F1 score macro: 0.3716\n",
      "TabTransformer Test Accuracy: 0.6521739130434783\n",
      "Epoch [283/300], Loss: 0.0320\n",
      "TabTransformer F1 score macro: 0.3792\n",
      "TabTransformer Test Accuracy: 0.6570048309178744\n",
      "Epoch [284/300], Loss: 0.0975\n",
      "TabTransformer F1 score macro: 0.3768\n",
      "TabTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [285/300], Loss: 0.0194\n",
      "TabTransformer F1 score macro: 0.3602\n",
      "TabTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [286/300], Loss: 0.0816\n",
      "TabTransformer F1 score macro: 0.3699\n",
      "TabTransformer Test Accuracy: 0.6521739130434783\n",
      "Epoch [287/300], Loss: 0.0098\n",
      "TabTransformer F1 score macro: 0.3674\n",
      "TabTransformer Test Accuracy: 0.6521739130434783\n",
      "Epoch [288/300], Loss: 0.0230\n",
      "TabTransformer F1 score macro: 0.3569\n",
      "TabTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [289/300], Loss: 0.1422\n",
      "TabTransformer F1 score macro: 0.3749\n",
      "TabTransformer Test Accuracy: 0.6570048309178744\n",
      "Epoch [290/300], Loss: 0.0566\n",
      "TabTransformer F1 score macro: 0.3658\n",
      "TabTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [291/300], Loss: 0.1062\n",
      "TabTransformer F1 score macro: 0.3510\n",
      "TabTransformer Test Accuracy: 0.6376811594202898\n",
      "Epoch [292/300], Loss: 0.1822\n",
      "TabTransformer F1 score macro: 0.3774\n",
      "TabTransformer Test Accuracy: 0.6570048309178744\n",
      "Epoch [293/300], Loss: 0.2171\n",
      "TabTransformer F1 score macro: 0.3497\n",
      "TabTransformer Test Accuracy: 0.642512077294686\n",
      "Epoch [294/300], Loss: 0.0894\n",
      "TabTransformer F1 score macro: 0.3696\n",
      "TabTransformer Test Accuracy: 0.6521739130434783\n",
      "Epoch [295/300], Loss: 0.0496\n",
      "TabTransformer F1 score macro: 0.3798\n",
      "TabTransformer Test Accuracy: 0.6570048309178744\n",
      "Epoch [296/300], Loss: 0.0726\n",
      "TabTransformer F1 score macro: 0.3607\n",
      "TabTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [297/300], Loss: 0.0109\n",
      "TabTransformer F1 score macro: 0.3805\n",
      "TabTransformer Test Accuracy: 0.6521739130434783\n",
      "Epoch [298/300], Loss: 0.2870\n",
      "TabTransformer F1 score macro: 0.3566\n",
      "TabTransformer Test Accuracy: 0.6473429951690821\n",
      "Epoch [299/300], Loss: 0.1407\n",
      "TabTransformer F1 score macro: 0.3745\n",
      "TabTransformer Test Accuracy: 0.6521739130434783\n",
      "Epoch [300/300], Loss: 0.1257\n",
      "TabTransformer F1 score macro: 0.3651\n",
      "TabTransformer Test Accuracy: 0.6521739130434783\n"
     ]
    }
   ],
   "source": [
    "# ============== TabTransformer ==============\n",
    "# TabTransformer: Tabular Data Modeling Using Contextual Embeddings\n",
    "def print_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        allocated = torch.cuda.memory_allocated(device) / 1024**3  # 转换为GB\n",
    "        total_memory = torch.cuda.get_device_properties(device).total_memory\n",
    "        print(f\"Allocated={allocated:.2f} GB, Total={total_memory / 1024**3:.2f} GB\")\n",
    "    else:\n",
    "        print(\"GPU unavaliable\")\n",
    "\n",
    "\n",
    "\n",
    "cat_cardinalities = [len(torch.unique(X_cat_tensor[:, i])) for i in range(X_cat_tensor.shape[1])]\n",
    "output_dim = 211\n",
    "model = TabTransformer(\n",
    "    categories = tuple(cat_cardinalities), \n",
    "    num_continuous = len(cont_cols),               \n",
    "    dim = 16,                            \n",
    "    dim_out = output_dim,                        \n",
    "    depth = 4,                           \n",
    "    heads = 4,                          \n",
    "    attn_dropout = 0.1,                  \n",
    "    ff_dropout = 0.1,                    \n",
    "    mlp_hidden_mults = (2, 1),           \n",
    "    mlp_act = nn.ReLU(),                 \n",
    "    continuous_mean_std = None,  \n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)  \n",
    "num_epochs = 300\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(X_cat_train, X_cont_train, y_train_nn)\n",
    "test_dataset = TensorDataset(X_cat_test, X_cont_test, y_test_nn)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# train\n",
    "for epoch in range(num_epochs):  \n",
    "    model.train()  \n",
    "    optimizer.zero_grad()\n",
    "    for batch_idx, (X_cat, X_cont, y) in enumerate(train_loader):  \n",
    "        X_cat = X_cat.to(device)\n",
    "        X_cont = X_cont.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        output = model(X_cat, X_cont)  \n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "    if (epoch+1) % 1 == 0:  \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')  \n",
    "\n",
    "        # eval\n",
    "        model.eval()\n",
    "        all_preds = []  \n",
    "        with torch.no_grad():  \n",
    "            for X_cat, X_cont, y in test_loader:\n",
    "                X_cat = X_cat.to(device)\n",
    "                X_cont = X_cont.to(device)\n",
    "                y = y.to(device)\n",
    "                \n",
    "                output = model(X_cat, X_cont)  \n",
    "                preds = output.argmax(dim=1)\n",
    "                all_preds.append(preds)\n",
    "        y_pred_nn = torch.cat(all_preds, dim=0).cpu()\n",
    "        f1_macro_nn = f1_score(y_test_nn, y_pred_nn, average='macro')\n",
    "        print(f'TabTransformer F1 score macro: {f1_macro_nn:.4f}') \n",
    "        print('TabTransformer Test Accuracy:', accuracy_score(y_test_nn, y_pred_nn))\n",
    "# ============== TabTransformer =============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 5.3299\n",
      "Node F1 score macro: 0.0095\n",
      "Node Test Accuracy: 0.043478260869565216\n",
      "Epoch [2/200], Loss: 5.2955\n",
      "Node F1 score macro: 0.0004\n",
      "Node Test Accuracy: 0.01932367149758454\n",
      "Epoch [3/200], Loss: 5.2489\n",
      "Node F1 score macro: 0.0004\n",
      "Node Test Accuracy: 0.01932367149758454\n",
      "Epoch [4/200], Loss: 5.2489\n",
      "Node F1 score macro: 0.0004\n",
      "Node Test Accuracy: 0.01932367149758454\n",
      "Epoch [5/200], Loss: 5.1917\n",
      "Node F1 score macro: 0.0004\n",
      "Node Test Accuracy: 0.01932367149758454\n",
      "Epoch [6/200], Loss: 5.2619\n",
      "Node F1 score macro: 0.0004\n",
      "Node Test Accuracy: 0.01932367149758454\n",
      "Epoch [7/200], Loss: 5.2510\n",
      "Node F1 score macro: 0.0004\n",
      "Node Test Accuracy: 0.01932367149758454\n",
      "Epoch [8/200], Loss: 5.2444\n",
      "Node F1 score macro: 0.0059\n",
      "Node Test Accuracy: 0.03864734299516908\n",
      "Epoch [9/200], Loss: 5.1847\n",
      "Node F1 score macro: 0.0055\n",
      "Node Test Accuracy: 0.03864734299516908\n",
      "Epoch [10/200], Loss: 5.2297\n",
      "Node F1 score macro: 0.0037\n",
      "Node Test Accuracy: 0.03864734299516908\n",
      "Epoch [11/200], Loss: 5.2140\n",
      "Node F1 score macro: 0.0030\n",
      "Node Test Accuracy: 0.04830917874396135\n",
      "Epoch [12/200], Loss: 5.2348\n",
      "Node F1 score macro: 0.0059\n",
      "Node Test Accuracy: 0.03864734299516908\n",
      "Epoch [13/200], Loss: 5.1644\n",
      "Node F1 score macro: 0.0116\n",
      "Node Test Accuracy: 0.06763285024154589\n",
      "Epoch [14/200], Loss: 5.1498\n",
      "Node F1 score macro: 0.0113\n",
      "Node Test Accuracy: 0.06763285024154589\n",
      "Epoch [15/200], Loss: 5.1898\n",
      "Node F1 score macro: 0.0120\n",
      "Node Test Accuracy: 0.06763285024154589\n",
      "Epoch [16/200], Loss: 5.1329\n",
      "Node F1 score macro: 0.0254\n",
      "Node Test Accuracy: 0.09178743961352658\n",
      "Epoch [17/200], Loss: 5.1164\n",
      "Node F1 score macro: 0.0294\n",
      "Node Test Accuracy: 0.0966183574879227\n",
      "Epoch [18/200], Loss: 5.1512\n",
      "Node F1 score macro: 0.0288\n",
      "Node Test Accuracy: 0.0966183574879227\n",
      "Epoch [19/200], Loss: 5.1065\n",
      "Node F1 score macro: 0.0333\n",
      "Node Test Accuracy: 0.12560386473429952\n",
      "Epoch [20/200], Loss: 5.0936\n",
      "Node F1 score macro: 0.0337\n",
      "Node Test Accuracy: 0.13043478260869565\n",
      "Epoch [21/200], Loss: 5.0504\n",
      "Node F1 score macro: 0.0429\n",
      "Node Test Accuracy: 0.14492753623188406\n",
      "Epoch [22/200], Loss: 5.0257\n",
      "Node F1 score macro: 0.0376\n",
      "Node Test Accuracy: 0.15458937198067632\n",
      "Epoch [23/200], Loss: 5.0751\n",
      "Node F1 score macro: 0.0450\n",
      "Node Test Accuracy: 0.1497584541062802\n",
      "Epoch [24/200], Loss: 4.9671\n",
      "Node F1 score macro: 0.0435\n",
      "Node Test Accuracy: 0.2028985507246377\n",
      "Epoch [25/200], Loss: 5.0446\n",
      "Node F1 score macro: 0.0487\n",
      "Node Test Accuracy: 0.15458937198067632\n",
      "Epoch [26/200], Loss: 5.0979\n",
      "Node F1 score macro: 0.0520\n",
      "Node Test Accuracy: 0.178743961352657\n",
      "Epoch [27/200], Loss: 5.0860\n",
      "Node F1 score macro: 0.0628\n",
      "Node Test Accuracy: 0.2318840579710145\n",
      "Epoch [28/200], Loss: 5.0220\n",
      "Node F1 score macro: 0.0641\n",
      "Node Test Accuracy: 0.2028985507246377\n",
      "Epoch [29/200], Loss: 5.0363\n",
      "Node F1 score macro: 0.0673\n",
      "Node Test Accuracy: 0.23671497584541062\n",
      "Epoch [30/200], Loss: 5.0326\n",
      "Node F1 score macro: 0.1059\n",
      "Node Test Accuracy: 0.2560386473429952\n",
      "Epoch [31/200], Loss: 4.9406\n",
      "Node F1 score macro: 0.1183\n",
      "Node Test Accuracy: 0.2898550724637681\n",
      "Epoch [32/200], Loss: 5.0063\n",
      "Node F1 score macro: 0.1175\n",
      "Node Test Accuracy: 0.2995169082125604\n",
      "Epoch [33/200], Loss: 4.9459\n",
      "Node F1 score macro: 0.1316\n",
      "Node Test Accuracy: 0.2995169082125604\n",
      "Epoch [34/200], Loss: 4.8980\n",
      "Node F1 score macro: 0.1275\n",
      "Node Test Accuracy: 0.3140096618357488\n",
      "Epoch [35/200], Loss: 4.9697\n",
      "Node F1 score macro: 0.1302\n",
      "Node Test Accuracy: 0.30917874396135264\n",
      "Epoch [36/200], Loss: 4.9581\n",
      "Node F1 score macro: 0.1599\n",
      "Node Test Accuracy: 0.3285024154589372\n",
      "Epoch [37/200], Loss: 4.8778\n",
      "Node F1 score macro: 0.1602\n",
      "Node Test Accuracy: 0.3333333333333333\n",
      "Epoch [38/200], Loss: 4.9382\n",
      "Node F1 score macro: 0.1666\n",
      "Node Test Accuracy: 0.3719806763285024\n",
      "Epoch [39/200], Loss: 4.8327\n",
      "Node F1 score macro: 0.1848\n",
      "Node Test Accuracy: 0.38164251207729466\n",
      "Epoch [40/200], Loss: 4.9562\n",
      "Node F1 score macro: 0.1805\n",
      "Node Test Accuracy: 0.3671497584541063\n",
      "Epoch [41/200], Loss: 4.9622\n",
      "Node F1 score macro: 0.2318\n",
      "Node Test Accuracy: 0.4492753623188406\n",
      "Epoch [42/200], Loss: 4.8004\n",
      "Node F1 score macro: 0.2215\n",
      "Node Test Accuracy: 0.43478260869565216\n",
      "Epoch [43/200], Loss: 4.8764\n",
      "Node F1 score macro: 0.2298\n",
      "Node Test Accuracy: 0.4057971014492754\n",
      "Epoch [44/200], Loss: 4.8371\n",
      "Node F1 score macro: 0.2513\n",
      "Node Test Accuracy: 0.463768115942029\n",
      "Epoch [45/200], Loss: 4.8437\n",
      "Node F1 score macro: 0.2401\n",
      "Node Test Accuracy: 0.463768115942029\n",
      "Epoch [46/200], Loss: 4.7857\n",
      "Node F1 score macro: 0.2461\n",
      "Node Test Accuracy: 0.463768115942029\n",
      "Epoch [47/200], Loss: 4.8275\n",
      "Node F1 score macro: 0.2603\n",
      "Node Test Accuracy: 0.4782608695652174\n",
      "Epoch [48/200], Loss: 4.7437\n",
      "Node F1 score macro: 0.2651\n",
      "Node Test Accuracy: 0.48792270531400966\n",
      "Epoch [49/200], Loss: 4.7849\n",
      "Node F1 score macro: 0.2515\n",
      "Node Test Accuracy: 0.4782608695652174\n",
      "Epoch [50/200], Loss: 4.7954\n",
      "Node F1 score macro: 0.2864\n",
      "Node Test Accuracy: 0.5024154589371981\n",
      "Epoch [51/200], Loss: 4.8349\n",
      "Node F1 score macro: 0.3002\n",
      "Node Test Accuracy: 0.5169082125603864\n",
      "Epoch [52/200], Loss: 4.7098\n",
      "Node F1 score macro: 0.3141\n",
      "Node Test Accuracy: 0.5217391304347826\n",
      "Epoch [53/200], Loss: 4.7761\n",
      "Node F1 score macro: 0.3266\n",
      "Node Test Accuracy: 0.5458937198067633\n",
      "Epoch [54/200], Loss: 4.8326\n",
      "Node F1 score macro: 0.3407\n",
      "Node Test Accuracy: 0.5555555555555556\n",
      "Epoch [55/200], Loss: 4.8072\n",
      "Node F1 score macro: 0.3518\n",
      "Node Test Accuracy: 0.5652173913043478\n",
      "Epoch [56/200], Loss: 4.7347\n",
      "Node F1 score macro: 0.3399\n",
      "Node Test Accuracy: 0.5652173913043478\n",
      "Epoch [57/200], Loss: 4.6884\n",
      "Node F1 score macro: 0.3521\n",
      "Node Test Accuracy: 0.5700483091787439\n",
      "Epoch [58/200], Loss: 4.6678\n",
      "Node F1 score macro: 0.3880\n",
      "Node Test Accuracy: 0.5942028985507246\n",
      "Epoch [59/200], Loss: 4.6270\n",
      "Node F1 score macro: 0.3661\n",
      "Node Test Accuracy: 0.5748792270531401\n",
      "Epoch [60/200], Loss: 4.6624\n",
      "Node F1 score macro: 0.3562\n",
      "Node Test Accuracy: 0.5748792270531401\n",
      "Epoch [61/200], Loss: 4.6720\n",
      "Node F1 score macro: 0.3869\n",
      "Node Test Accuracy: 0.5990338164251208\n",
      "Epoch [62/200], Loss: 4.6697\n",
      "Node F1 score macro: 0.4054\n",
      "Node Test Accuracy: 0.6038647342995169\n",
      "Epoch [63/200], Loss: 4.6494\n",
      "Node F1 score macro: 0.3900\n",
      "Node Test Accuracy: 0.5893719806763285\n",
      "Epoch [64/200], Loss: 4.5493\n",
      "Node F1 score macro: 0.3991\n",
      "Node Test Accuracy: 0.6231884057971014\n",
      "Epoch [65/200], Loss: 4.6688\n",
      "Node F1 score macro: 0.4244\n",
      "Node Test Accuracy: 0.6280193236714976\n",
      "Epoch [66/200], Loss: 4.6247\n",
      "Node F1 score macro: 0.4215\n",
      "Node Test Accuracy: 0.6086956521739131\n",
      "Epoch [67/200], Loss: 4.5954\n",
      "Node F1 score macro: 0.4133\n",
      "Node Test Accuracy: 0.6280193236714976\n",
      "Epoch [68/200], Loss: 4.6222\n",
      "Node F1 score macro: 0.4233\n",
      "Node Test Accuracy: 0.642512077294686\n",
      "Epoch [69/200], Loss: 4.6449\n",
      "Node F1 score macro: 0.4452\n",
      "Node Test Accuracy: 0.6473429951690821\n",
      "Epoch [70/200], Loss: 4.6247\n",
      "Node F1 score macro: 0.4345\n",
      "Node Test Accuracy: 0.642512077294686\n",
      "Epoch [71/200], Loss: 4.6349\n",
      "Node F1 score macro: 0.4439\n",
      "Node Test Accuracy: 0.6570048309178744\n",
      "Epoch [72/200], Loss: 4.5958\n",
      "Node F1 score macro: 0.4489\n",
      "Node Test Accuracy: 0.6570048309178744\n",
      "Epoch [73/200], Loss: 4.5603\n",
      "Node F1 score macro: 0.4455\n",
      "Node Test Accuracy: 0.6570048309178744\n",
      "Epoch [74/200], Loss: 4.5596\n",
      "Node F1 score macro: 0.4469\n",
      "Node Test Accuracy: 0.6570048309178744\n",
      "Epoch [75/200], Loss: 4.5560\n",
      "Node F1 score macro: 0.4651\n",
      "Node Test Accuracy: 0.6666666666666666\n",
      "Epoch [76/200], Loss: 4.5216\n",
      "Node F1 score macro: 0.4771\n",
      "Node Test Accuracy: 0.6811594202898551\n",
      "Epoch [77/200], Loss: 4.4694\n",
      "Node F1 score macro: 0.4748\n",
      "Node Test Accuracy: 0.6811594202898551\n",
      "Epoch [78/200], Loss: 4.5011\n",
      "Node F1 score macro: 0.4758\n",
      "Node Test Accuracy: 0.6811594202898551\n",
      "Epoch [79/200], Loss: 4.5307\n",
      "Node F1 score macro: 0.4983\n",
      "Node Test Accuracy: 0.6956521739130435\n",
      "Epoch [80/200], Loss: 4.5240\n",
      "Node F1 score macro: 0.4942\n",
      "Node Test Accuracy: 0.6956521739130435\n",
      "Epoch [81/200], Loss: 4.5340\n",
      "Node F1 score macro: 0.5030\n",
      "Node Test Accuracy: 0.7004830917874396\n",
      "Epoch [82/200], Loss: 4.6525\n",
      "Node F1 score macro: 0.5188\n",
      "Node Test Accuracy: 0.7053140096618358\n",
      "Epoch [83/200], Loss: 4.5092\n",
      "Node F1 score macro: 0.5015\n",
      "Node Test Accuracy: 0.7004830917874396\n",
      "Epoch [84/200], Loss: 4.5197\n",
      "Node F1 score macro: 0.5029\n",
      "Node Test Accuracy: 0.7004830917874396\n",
      "Epoch [85/200], Loss: 4.4399\n",
      "Node F1 score macro: 0.5189\n",
      "Node Test Accuracy: 0.7101449275362319\n",
      "Epoch [86/200], Loss: 4.5096\n",
      "Node F1 score macro: 0.5190\n",
      "Node Test Accuracy: 0.7053140096618358\n",
      "Epoch [87/200], Loss: 4.4912\n",
      "Node F1 score macro: 0.5049\n",
      "Node Test Accuracy: 0.7004830917874396\n",
      "Epoch [88/200], Loss: 4.4814\n",
      "Node F1 score macro: 0.5284\n",
      "Node Test Accuracy: 0.7198067632850241\n",
      "Epoch [89/200], Loss: 4.5065\n",
      "Node F1 score macro: 0.5224\n",
      "Node Test Accuracy: 0.7101449275362319\n",
      "Epoch [90/200], Loss: 4.4802\n",
      "Node F1 score macro: 0.5271\n",
      "Node Test Accuracy: 0.714975845410628\n",
      "Epoch [91/200], Loss: 4.5269\n",
      "Node F1 score macro: 0.5379\n",
      "Node Test Accuracy: 0.7246376811594203\n",
      "Epoch [92/200], Loss: 4.4600\n",
      "Node F1 score macro: 0.5514\n",
      "Node Test Accuracy: 0.7294685990338164\n",
      "Epoch [93/200], Loss: 4.5682\n",
      "Node F1 score macro: 0.5347\n",
      "Node Test Accuracy: 0.7198067632850241\n",
      "Epoch [94/200], Loss: 4.4751\n",
      "Node F1 score macro: 0.5393\n",
      "Node Test Accuracy: 0.7246376811594203\n",
      "Epoch [95/200], Loss: 4.4228\n",
      "Node F1 score macro: 0.5383\n",
      "Node Test Accuracy: 0.7246376811594203\n",
      "Epoch [96/200], Loss: 4.4849\n",
      "Node F1 score macro: 0.5515\n",
      "Node Test Accuracy: 0.7294685990338164\n",
      "Epoch [97/200], Loss: 4.4213\n",
      "Node F1 score macro: 0.5523\n",
      "Node Test Accuracy: 0.7342995169082126\n",
      "Epoch [98/200], Loss: 4.4725\n",
      "Node F1 score macro: 0.5388\n",
      "Node Test Accuracy: 0.7246376811594203\n",
      "Epoch [99/200], Loss: 4.3777\n",
      "Node F1 score macro: 0.5421\n",
      "Node Test Accuracy: 0.7246376811594203\n",
      "Epoch [100/200], Loss: 4.5266\n",
      "Node F1 score macro: 0.5552\n",
      "Node Test Accuracy: 0.7342995169082126\n",
      "Epoch [101/200], Loss: 4.4528\n",
      "Node F1 score macro: 0.5505\n",
      "Node Test Accuracy: 0.7342995169082126\n",
      "Epoch [102/200], Loss: 4.4083\n",
      "Node F1 score macro: 0.5470\n",
      "Node Test Accuracy: 0.7294685990338164\n",
      "Epoch [103/200], Loss: 4.4253\n",
      "Node F1 score macro: 0.5502\n",
      "Node Test Accuracy: 0.7294685990338164\n",
      "Epoch [104/200], Loss: 4.4610\n",
      "Node F1 score macro: 0.5532\n",
      "Node Test Accuracy: 0.7342995169082126\n",
      "Epoch [105/200], Loss: 4.4174\n",
      "Node F1 score macro: 0.5490\n",
      "Node Test Accuracy: 0.7342995169082126\n",
      "Epoch [106/200], Loss: 4.4559\n",
      "Node F1 score macro: 0.5536\n",
      "Node Test Accuracy: 0.7342995169082126\n",
      "Epoch [107/200], Loss: 4.4401\n",
      "Node F1 score macro: 0.5600\n",
      "Node Test Accuracy: 0.7391304347826086\n",
      "Epoch [108/200], Loss: 4.4295\n",
      "Node F1 score macro: 0.5579\n",
      "Node Test Accuracy: 0.7391304347826086\n",
      "Epoch [109/200], Loss: 4.4402\n",
      "Node F1 score macro: 0.5673\n",
      "Node Test Accuracy: 0.7536231884057971\n",
      "Epoch [110/200], Loss: 4.4047\n",
      "Node F1 score macro: 0.5797\n",
      "Node Test Accuracy: 0.7536231884057971\n",
      "Epoch [111/200], Loss: 4.4204\n",
      "Node F1 score macro: 0.5722\n",
      "Node Test Accuracy: 0.748792270531401\n",
      "Epoch [112/200], Loss: 4.4807\n",
      "Node F1 score macro: 0.5719\n",
      "Node Test Accuracy: 0.7584541062801933\n",
      "Epoch [113/200], Loss: 4.4663\n",
      "Node F1 score macro: 0.5823\n",
      "Node Test Accuracy: 0.7632850241545893\n",
      "Epoch [114/200], Loss: 4.4108\n",
      "Node F1 score macro: 0.5823\n",
      "Node Test Accuracy: 0.7584541062801933\n",
      "Epoch [115/200], Loss: 4.3722\n",
      "Node F1 score macro: 0.5819\n",
      "Node Test Accuracy: 0.7584541062801933\n",
      "Epoch [116/200], Loss: 4.4271\n",
      "Node F1 score macro: 0.5811\n",
      "Node Test Accuracy: 0.7632850241545893\n",
      "Epoch [117/200], Loss: 4.3873\n",
      "Node F1 score macro: 0.5824\n",
      "Node Test Accuracy: 0.7584541062801933\n",
      "Epoch [118/200], Loss: 4.3839\n",
      "Node F1 score macro: 0.5791\n",
      "Node Test Accuracy: 0.7536231884057971\n",
      "Epoch [119/200], Loss: 4.3845\n",
      "Node F1 score macro: 0.5823\n",
      "Node Test Accuracy: 0.7632850241545893\n",
      "Epoch [120/200], Loss: 4.4000\n",
      "Node F1 score macro: 0.5823\n",
      "Node Test Accuracy: 0.7632850241545893\n",
      "Epoch [121/200], Loss: 4.3809\n",
      "Node F1 score macro: 0.5839\n",
      "Node Test Accuracy: 0.7632850241545893\n",
      "Epoch [122/200], Loss: 4.4360\n",
      "Node F1 score macro: 0.5823\n",
      "Node Test Accuracy: 0.7632850241545893\n",
      "Epoch [123/200], Loss: 4.3762\n",
      "Node F1 score macro: 0.5827\n",
      "Node Test Accuracy: 0.7632850241545893\n",
      "Epoch [124/200], Loss: 4.3869\n",
      "Node F1 score macro: 0.5934\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [125/200], Loss: 4.3370\n",
      "Node F1 score macro: 0.5843\n",
      "Node Test Accuracy: 0.7632850241545893\n",
      "Epoch [126/200], Loss: 4.3493\n",
      "Node F1 score macro: 0.5831\n",
      "Node Test Accuracy: 0.7632850241545893\n",
      "Epoch [127/200], Loss: 4.4006\n",
      "Node F1 score macro: 0.5938\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [128/200], Loss: 4.3659\n",
      "Node F1 score macro: 0.5934\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [129/200], Loss: 4.3893\n",
      "Node F1 score macro: 0.5836\n",
      "Node Test Accuracy: 0.7632850241545893\n",
      "Epoch [130/200], Loss: 4.3281\n",
      "Node F1 score macro: 0.5932\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [131/200], Loss: 4.3245\n",
      "Node F1 score macro: 0.5939\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [132/200], Loss: 4.3885\n",
      "Node F1 score macro: 0.5934\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [133/200], Loss: 4.2992\n",
      "Node F1 score macro: 0.5937\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [134/200], Loss: 4.3386\n",
      "Node F1 score macro: 0.5939\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [135/200], Loss: 4.2984\n",
      "Node F1 score macro: 0.5934\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [136/200], Loss: 4.3325\n",
      "Node F1 score macro: 0.5938\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [137/200], Loss: 4.3648\n",
      "Node F1 score macro: 0.5942\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [138/200], Loss: 4.3461\n",
      "Node F1 score macro: 0.5927\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [139/200], Loss: 4.3258\n",
      "Node F1 score macro: 0.5934\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [140/200], Loss: 4.3336\n",
      "Node F1 score macro: 0.5948\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [141/200], Loss: 4.3358\n",
      "Node F1 score macro: 0.5938\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [142/200], Loss: 4.3904\n",
      "Node F1 score macro: 0.5928\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [143/200], Loss: 4.3235\n",
      "Node F1 score macro: 0.5934\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [144/200], Loss: 4.3162\n",
      "Node F1 score macro: 0.5948\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [145/200], Loss: 4.3636\n",
      "Node F1 score macro: 0.5931\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [146/200], Loss: 4.3636\n",
      "Node F1 score macro: 0.5928\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [147/200], Loss: 4.3343\n",
      "Node F1 score macro: 0.5948\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [148/200], Loss: 4.3125\n",
      "Node F1 score macro: 0.5948\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [149/200], Loss: 4.3089\n",
      "Node F1 score macro: 0.5931\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [150/200], Loss: 4.3843\n",
      "Node F1 score macro: 0.5931\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [151/200], Loss: 4.3554\n",
      "Node F1 score macro: 0.5884\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [152/200], Loss: 4.3017\n",
      "Node F1 score macro: 0.5937\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [153/200], Loss: 4.2787\n",
      "Node F1 score macro: 0.5927\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [154/200], Loss: 4.2930\n",
      "Node F1 score macro: 0.5887\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [155/200], Loss: 4.2932\n",
      "Node F1 score macro: 0.5877\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [156/200], Loss: 4.3033\n",
      "Node F1 score macro: 0.5927\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [157/200], Loss: 4.2797\n",
      "Node F1 score macro: 0.5931\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [158/200], Loss: 4.3053\n",
      "Node F1 score macro: 0.5878\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [159/200], Loss: 4.3047\n",
      "Node F1 score macro: 0.5872\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [160/200], Loss: 4.3243\n",
      "Node F1 score macro: 0.5864\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [161/200], Loss: 4.3089\n",
      "Node F1 score macro: 0.5879\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [162/200], Loss: 4.3268\n",
      "Node F1 score macro: 0.5874\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [163/200], Loss: 4.2876\n",
      "Node F1 score macro: 0.5868\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [164/200], Loss: 4.2883\n",
      "Node F1 score macro: 0.5869\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [165/200], Loss: 4.2877\n",
      "Node F1 score macro: 0.5890\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [166/200], Loss: 4.2673\n",
      "Node F1 score macro: 0.5890\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [167/200], Loss: 4.2628\n",
      "Node F1 score macro: 0.5868\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [168/200], Loss: 4.3141\n",
      "Node F1 score macro: 0.5874\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [169/200], Loss: 4.2969\n",
      "Node F1 score macro: 0.5890\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [170/200], Loss: 4.2745\n",
      "Node F1 score macro: 0.5874\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [171/200], Loss: 4.2638\n",
      "Node F1 score macro: 0.5868\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [172/200], Loss: 4.2564\n",
      "Node F1 score macro: 0.5890\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [173/200], Loss: 4.2221\n",
      "Node F1 score macro: 0.5890\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [174/200], Loss: 4.2442\n",
      "Node F1 score macro: 0.5874\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [175/200], Loss: 4.2513\n",
      "Node F1 score macro: 0.5886\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [176/200], Loss: 4.1922\n",
      "Node F1 score macro: 0.5890\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [177/200], Loss: 4.2472\n",
      "Node F1 score macro: 0.5897\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [178/200], Loss: 4.2704\n",
      "Node F1 score macro: 0.5874\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [179/200], Loss: 4.2519\n",
      "Node F1 score macro: 0.5897\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [180/200], Loss: 4.2240\n",
      "Node F1 score macro: 0.5904\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [181/200], Loss: 4.2801\n",
      "Node F1 score macro: 0.5892\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [182/200], Loss: 4.2315\n",
      "Node F1 score macro: 0.5892\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [183/200], Loss: 4.2160\n",
      "Node F1 score macro: 0.5903\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [184/200], Loss: 4.2052\n",
      "Node F1 score macro: 0.5904\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [185/200], Loss: 4.2497\n",
      "Node F1 score macro: 0.5897\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [186/200], Loss: 4.2297\n",
      "Node F1 score macro: 0.5897\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [187/200], Loss: 4.2475\n",
      "Node F1 score macro: 0.5919\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [188/200], Loss: 4.1895\n",
      "Node F1 score macro: 0.5907\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [189/200], Loss: 4.2705\n",
      "Node F1 score macro: 0.5902\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [190/200], Loss: 4.1828\n",
      "Node F1 score macro: 0.5919\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [191/200], Loss: 4.2818\n",
      "Node F1 score macro: 0.5919\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [192/200], Loss: 4.2325\n",
      "Node F1 score macro: 0.5907\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [193/200], Loss: 4.2448\n",
      "Node F1 score macro: 0.5907\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [194/200], Loss: 4.2282\n",
      "Node F1 score macro: 0.5919\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [195/200], Loss: 4.2148\n",
      "Node F1 score macro: 0.5919\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [196/200], Loss: 4.2380\n",
      "Node F1 score macro: 0.5908\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [197/200], Loss: 4.2119\n",
      "Node F1 score macro: 0.5919\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [198/200], Loss: 4.2064\n",
      "Node F1 score macro: 0.5919\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [199/200], Loss: 4.1798\n",
      "Node F1 score macro: 0.5919\n",
      "Node Test Accuracy: 0.7681159420289855\n",
      "Epoch [200/200], Loss: 4.2758\n",
      "Node F1 score macro: 0.5919\n",
      "Node Test Accuracy: 0.7681159420289855\n"
     ]
    }
   ],
   "source": [
    "# ============== NODE ==============\n",
    "# Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data\n",
    "import lib\n",
    "\n",
    "num_classes = 211\n",
    "model = nn.Sequential(\n",
    "    lib.DenseBlock(X_train_nn.shape[1], layer_dim=128, num_layers=8, tree_dim=num_classes+1, flatten_output=False, depth=6, choice_function=lib.entmax15, bin_function=lib.entmoid15),\n",
    "    lib.Lambda(lambda x: x[..., :num_classes].mean(dim=-2)),\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)  \n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = TensorDataset(X_train_nn, y_train_nn)\n",
    "test_dataset = TensorDataset(X_test_nn, y_test_nn)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# train\n",
    "for epoch in range(num_epochs):  \n",
    "    model.train()  \n",
    "    optimizer.zero_grad()\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):  \n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        output = model(X)  \n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "    if (epoch+1) % 1 == 0:  \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')  \n",
    "\n",
    "        # eval\n",
    "        model.eval()\n",
    "        all_preds = []  \n",
    "        with torch.no_grad():  \n",
    "            for X, y in test_loader:\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                \n",
    "                output = model(X)  \n",
    "                preds = output.argmax(dim=1)\n",
    "                all_preds.append(preds)\n",
    "        y_pred_nn = torch.cat(all_preds, dim=0).cpu()\n",
    "        f1_macro_nn = f1_score(y_test_nn, y_pred_nn, average='macro')\n",
    "        print(f'Node F1 score macro: {f1_macro_nn:.4f}') \n",
    "        print('Node Test Accuracy:', accuracy_score(y_test_nn, y_pred_nn))\n",
    "# ============== NODE =============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------ ML methods ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(data[features], prefix=None, prefix_sep='_')\n",
    "y = data['Disease_id']\n",
    "y = le.fit_transform(y)\n",
    "label_mappings = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost F1 score macro: 0.36\n",
      "XGBoost Test Accuracy: 0.6618357487922706\n",
      "Catboost F1 score macro: 0.41\n",
      "catboost Test Accuracy: 0.6570048309178744\n"
     ]
    }
   ],
   "source": [
    "# ============= XGBoost =============\n",
    "params = {\n",
    "    'objective': 'multi:softmax', \n",
    "    'eval_metric': 'mlogloss', \n",
    "    'num_class': 211,\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cpu',\n",
    "    \"random_state\": 5,\n",
    "    }\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, missing=-1)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, missing=-1)\n",
    "model = xgb.train(params, dtrain, evals=[(dtest, 'test')], num_boost_round=200, verbose_eval=False)\n",
    "y_pred_xgb = model.predict(dtest)\n",
    "f1_macro_xgb = f1_score(y_test, y_pred_xgb, average='macro')\n",
    "\n",
    "print(f'XGBoost F1 score macro: {f1_macro_xgb:.2f}')\n",
    "print('XGBoost Test Accuracy:', accuracy_score(y_test, y_pred_xgb))\n",
    "# ============= XGBoost =============\n",
    "\n",
    "\n",
    "# ============= Catboost =============\n",
    "cat = CatBoostClassifier(iterations=300, learning_rate=0.1, random_seed=5)\n",
    "cat.fit(X_train, y_train, verbose=0)\n",
    "y_pred_cat = cat.predict(X_test)\n",
    "f1_macro_cat = f1_score(y_test, y_pred_cat, average='macro')\n",
    "print(f'Catboost F1 score macro: {f1_macro_cat:.2f}')\n",
    "print('catboost Test Accuracy:', accuracy_score(y_test, y_pred_cat))\n",
    "# ============= Catboost ============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM F1 score macro: 0.3352\n",
      "SVM Test Accuracy: 0.642512077294686\n",
      "Decision Tree F1 score macro: 0.5137\n",
      "Decision Tree Test Accuracy: 0.7439613526570048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 score macro: 0.4142\n",
      "Logistic Regression Test Accuracy: 0.7053140096618358\n",
      "rf F1 score macro: 0.5225\n",
      "rf Test Accuracy: 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "\n",
    "# ============== SVM ==============\n",
    "svm = SVC(kernel='rbf', C=50, gamma='scale')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "f1_macro_svm = f1_score(y_test, y_pred_svm, average='macro')\n",
    "print(f'SVM F1 score macro: {f1_macro_svm:.4f}')\n",
    "print('SVM Test Accuracy:', accuracy_score(y_test, y_pred_svm))\n",
    "# ============== SVM ==============\n",
    "\n",
    "\n",
    "\n",
    "# ============== Decision Tree ==============\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "f1_macro_dt = f1_score(y_test, y_pred_dt, average='macro')\n",
    "print(f'Decision Tree F1 score macro: {f1_macro_dt:.4f}') \n",
    "print('Decision Tree Test Accuracy:', accuracy_score(y_test, y_pred_dt))\n",
    "# ============== Decision Tree ==============\n",
    "\n",
    "\n",
    "\n",
    "# ============== Logistic Regression ==============\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "f1_macro_lr = f1_score(y_test, y_pred_lr, average='macro')\n",
    "print(f'Logistic Regression F1 score macro: {f1_macro_lr:.4f}')\n",
    "print('Logistic Regression Test Accuracy:', accuracy_score(y_test, y_pred_lr))\n",
    "# ========== Logistic Regression ==========\n",
    "\n",
    "\n",
    "\n",
    "# ============== Random Forest ==============\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "print(f'rf F1 score macro: {f1_macro:.4f}')\n",
    "print('rf Test Accuracy:', accuracy_score(y_test, y_pred))\n",
    "# ============== Random Forest =============="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
